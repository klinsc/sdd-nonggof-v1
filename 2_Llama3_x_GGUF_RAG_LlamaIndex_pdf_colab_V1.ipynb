{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/klinsc/sdd-nonggof-v1/blob/main/2_Llama3_x_GGUF_RAG_LlamaIndex_pdf_colab_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlVz3NHxgk0h"
      },
      "source": [
        "<p>\n",
        "    <img src=\"https://cdn-uploads.huggingface.co/production/uploads/6424f01ea4f3051f54dbbd85/oqVQ04b5KiGt5WOWJmYt8.png\" alt=\"LlamaIndex\" width=\"100\" height=\"100\">\n",
        "    <img src=\"https://cdn4.iconfinder.com/data/icons/file-extensions-1/64/pdfs-512.png\" alt=\"PDF\" width=\"100\" height=\"100\">\n",
        "    <img src=\"https://huggingface.co/front/assets/huggingface_logo-noborder.svg\" alt=\"PDF\" width=\"100\" height=\"100\">\n",
        "</p>\n",
        "\n",
        "# LlamaIndex\n",
        "## [Youtube Video covering this notebook](https://youtu.be/QNKeNiRjtGQ?si=UFH9WL5nXvmj2EM1)\n",
        "- [LlamaIndex Website](https://www.llamaindex.ai/)\n",
        "- [LangChain Website](https://python.langchain.com/docs/get_started/introduction)\n",
        "-[Retrieval-Augmented Generation (RAG)](https://research.ibm.com/blog/retrieval-augmented-generation-RAG)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YMfROowrS-kG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "520f51cb-4978-4cd4-c56d-b3043b07943c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoDC_DKkj6Ga"
      },
      "source": [
        "## Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nW_0yKusLRWK"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install llama-index\n",
        "!pip install llama-index-llms-llama-cpp\n",
        "!pip install llama-index-embeddings-huggingface\n",
        "\n",
        "!pip install llama-index-postprocessor-flag-embedding-reranker\n",
        "!pip install git+https://github.com/FlagOpen/FlagEmbedding.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4HkW33bQE2VI",
        "outputId": "22b600e7-712b-49d5-fb3c-429a14cbfc51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                                           Version\n",
            "------------------------------------------------- -------------------\n",
            "absl-py                                           1.4.0\n",
            "accelerate                                        1.7.0\n",
            "aiohappyeyeballs                                  2.6.1\n",
            "aiohttp                                           3.11.15\n",
            "aiosignal                                         1.3.2\n",
            "aiosqlite                                         0.21.0\n",
            "alabaster                                         1.0.0\n",
            "albucore                                          0.0.24\n",
            "albumentations                                    2.0.7\n",
            "ale-py                                            0.11.0\n",
            "altair                                            5.5.0\n",
            "annotated-types                                   0.7.0\n",
            "antlr4-python3-runtime                            4.9.3\n",
            "anyio                                             4.9.0\n",
            "argon2-cffi                                       23.1.0\n",
            "argon2-cffi-bindings                              21.2.0\n",
            "array_record                                      0.7.2\n",
            "arviz                                             0.21.0\n",
            "astropy                                           7.1.0\n",
            "astropy-iers-data                                 0.2025.5.19.0.38.36\n",
            "astunparse                                        1.6.3\n",
            "atpublic                                          5.1\n",
            "attrs                                             25.3.0\n",
            "audioread                                         3.0.1\n",
            "autograd                                          1.8.0\n",
            "babel                                             2.17.0\n",
            "backcall                                          0.2.0\n",
            "backports.tarfile                                 1.2.0\n",
            "banks                                             2.1.2\n",
            "beautifulsoup4                                    4.13.4\n",
            "betterproto                                       2.0.0b6\n",
            "bigframes                                         2.4.0\n",
            "bigquery-magics                                   0.9.0\n",
            "bleach                                            6.2.0\n",
            "blinker                                           1.9.0\n",
            "blis                                              1.3.0\n",
            "blobfile                                          3.0.0\n",
            "blosc2                                            3.3.3\n",
            "bokeh                                             3.7.3\n",
            "Bottleneck                                        1.4.2\n",
            "bqplot                                            0.12.45\n",
            "branca                                            0.8.1\n",
            "build                                             1.2.2.post1\n",
            "CacheControl                                      0.14.3\n",
            "cachetools                                        5.5.2\n",
            "catalogue                                         2.0.10\n",
            "cbor                                              1.0.0\n",
            "certifi                                           2025.4.26\n",
            "cffi                                              1.17.1\n",
            "chardet                                           5.2.0\n",
            "charset-normalizer                                3.4.2\n",
            "chex                                              0.1.89\n",
            "clarabel                                          0.10.0\n",
            "click                                             8.2.1\n",
            "cloudpathlib                                      0.21.1\n",
            "cloudpickle                                       3.1.1\n",
            "cmake                                             3.31.6\n",
            "cmdstanpy                                         1.2.5\n",
            "colorama                                          0.4.6\n",
            "colorcet                                          3.1.0\n",
            "colorlover                                        0.3.0\n",
            "colour                                            0.1.5\n",
            "community                                         1.0.0b1\n",
            "confection                                        0.1.5\n",
            "cons                                              0.4.6\n",
            "contourpy                                         1.3.2\n",
            "cramjam                                           2.10.0\n",
            "cryptography                                      43.0.3\n",
            "cuda-python                                       12.6.2.post1\n",
            "cudf-cu12                                         25.2.1\n",
            "cudf-polars-cu12                                  25.2.2\n",
            "cufflinks                                         0.17.3\n",
            "cuml-cu12                                         25.2.1\n",
            "cupy-cuda12x                                      13.3.0\n",
            "curl_cffi                                         0.11.1\n",
            "cuvs-cu12                                         25.2.1\n",
            "cvxopt                                            1.3.2\n",
            "cvxpy                                             1.6.5\n",
            "cycler                                            0.12.1\n",
            "cyipopt                                           1.5.0\n",
            "cymem                                             2.0.11\n",
            "Cython                                            3.0.12\n",
            "dask                                              2024.12.1\n",
            "dask-cuda                                         25.2.0\n",
            "dask-cudf-cu12                                    25.2.2\n",
            "dask-expr                                         1.1.21\n",
            "dataclasses-json                                  0.6.7\n",
            "dataproc-spark-connect                            0.7.4\n",
            "datascience                                       0.17.6\n",
            "datasets                                          3.6.0\n",
            "db-dtypes                                         1.4.3\n",
            "dbus-python                                       1.2.18\n",
            "debugpy                                           1.8.0\n",
            "decorator                                         4.4.2\n",
            "defusedxml                                        0.7.1\n",
            "Deprecated                                        1.2.18\n",
            "diffusers                                         0.33.1\n",
            "dill                                              0.3.7\n",
            "dirtyjson                                         1.0.8\n",
            "diskcache                                         5.6.3\n",
            "distributed                                       2024.12.1\n",
            "distributed-ucxx-cu12                             0.42.0\n",
            "distro                                            1.9.0\n",
            "dlib                                              19.24.6\n",
            "dm-tree                                           0.1.9\n",
            "docker-pycreds                                    0.4.0\n",
            "docstring_parser                                  0.16\n",
            "docutils                                          0.21.2\n",
            "dopamine_rl                                       4.1.2\n",
            "duckdb                                            1.2.2\n",
            "earthengine-api                                   1.5.15\n",
            "easydict                                          1.13\n",
            "editdistance                                      0.8.1\n",
            "eerepr                                            0.1.2\n",
            "einops                                            0.8.1\n",
            "en_core_web_sm                                    3.8.0\n",
            "entrypoints                                       0.4\n",
            "et_xmlfile                                        2.0.0\n",
            "etils                                             1.12.2\n",
            "etuples                                           0.3.9\n",
            "Farama-Notifications                              0.0.4\n",
            "fastai                                            2.7.19\n",
            "fastcore                                          1.7.29\n",
            "fastdownload                                      0.0.7\n",
            "fastjsonschema                                    2.21.1\n",
            "fastprogress                                      1.0.3\n",
            "fastrlock                                         0.8.3\n",
            "filelock                                          3.18.0\n",
            "filetype                                          1.2.0\n",
            "firebase-admin                                    6.8.0\n",
            "FlagEmbedding                                     1.3.5\n",
            "Flask                                             3.1.1\n",
            "flatbuffers                                       25.2.10\n",
            "flax                                              0.10.6\n",
            "folium                                            0.19.6\n",
            "fonttools                                         4.58.0\n",
            "frozendict                                        2.4.6\n",
            "frozenlist                                        1.6.0\n",
            "fsspec                                            2025.3.0\n",
            "future                                            1.0.0\n",
            "gast                                              0.6.0\n",
            "gcsfs                                             2025.3.2\n",
            "GDAL                                              3.8.4\n",
            "gdown                                             5.2.0\n",
            "geemap                                            0.35.3\n",
            "geocoder                                          1.38.1\n",
            "geographiclib                                     2.0\n",
            "geopandas                                         1.0.1\n",
            "geopy                                             2.4.1\n",
            "gin-config                                        0.5.0\n",
            "gitdb                                             4.0.12\n",
            "GitPython                                         3.1.44\n",
            "glob2                                             0.7\n",
            "google                                            2.0.3\n",
            "google-ai-generativelanguage                      0.6.15\n",
            "google-api-core                                   2.24.2\n",
            "google-api-python-client                          2.169.0\n",
            "google-auth                                       2.38.0\n",
            "google-auth-httplib2                              0.2.0\n",
            "google-auth-oauthlib                              1.2.2\n",
            "google-cloud-aiplatform                           1.93.1\n",
            "google-cloud-bigquery                             3.33.0\n",
            "google-cloud-bigquery-connection                  1.18.2\n",
            "google-cloud-bigquery-storage                     2.31.0\n",
            "google-cloud-core                                 2.4.3\n",
            "google-cloud-dataproc                             5.18.1\n",
            "google-cloud-datastore                            2.21.0\n",
            "google-cloud-firestore                            2.20.2\n",
            "google-cloud-functions                            1.20.3\n",
            "google-cloud-iam                                  2.19.0\n",
            "google-cloud-language                             2.17.1\n",
            "google-cloud-resource-manager                     1.14.2\n",
            "google-cloud-spanner                              3.54.0\n",
            "google-cloud-storage                              2.19.0\n",
            "google-cloud-translate                            3.20.2\n",
            "google-colab                                      1.0.0\n",
            "google-crc32c                                     1.7.1\n",
            "google-genai                                      1.16.1\n",
            "google-generativeai                               0.8.5\n",
            "google-pasta                                      0.2.0\n",
            "google-resumable-media                            2.7.2\n",
            "googleapis-common-protos                          1.70.0\n",
            "googledrivedownloader                             1.1.0\n",
            "graphviz                                          0.20.3\n",
            "greenlet                                          3.2.2\n",
            "griffe                                            1.7.3\n",
            "grpc-google-iam-v1                                0.14.2\n",
            "grpc-interceptor                                  0.15.4\n",
            "grpcio                                            1.71.0\n",
            "grpcio-status                                     1.71.0\n",
            "grpclib                                           0.4.8\n",
            "gspread                                           6.2.1\n",
            "gspread-dataframe                                 4.0.0\n",
            "gym                                               0.25.2\n",
            "gym-notices                                       0.0.8\n",
            "gymnasium                                         1.1.1\n",
            "h11                                               0.16.0\n",
            "h2                                                4.2.0\n",
            "h5netcdf                                          1.6.1\n",
            "h5py                                              3.13.0\n",
            "hdbscan                                           0.8.40\n",
            "hf_transfer                                       0.1.9\n",
            "highspy                                           1.10.0\n",
            "holidays                                          0.73\n",
            "holoviews                                         1.20.2\n",
            "hpack                                             4.1.0\n",
            "html5lib                                          1.1\n",
            "httpcore                                          1.0.9\n",
            "httpimport                                        1.4.1\n",
            "httplib2                                          0.22.0\n",
            "httpx                                             0.28.1\n",
            "huggingface-hub                                   0.31.4\n",
            "humanize                                          4.12.3\n",
            "hyperframe                                        6.1.0\n",
            "hyperopt                                          0.2.7\n",
            "ibis-framework                                    9.5.0\n",
            "idna                                              3.10\n",
            "ijson                                             3.4.0\n",
            "imageio                                           2.37.0\n",
            "imageio-ffmpeg                                    0.6.0\n",
            "imagesize                                         1.4.1\n",
            "imbalanced-learn                                  0.13.0\n",
            "immutabledict                                     4.2.1\n",
            "importlib_metadata                                8.7.0\n",
            "importlib_resources                               6.5.2\n",
            "imutils                                           0.5.4\n",
            "inflect                                           7.5.0\n",
            "iniconfig                                         2.1.0\n",
            "inscriptis                                        2.6.0\n",
            "intel-cmplr-lib-ur                                2025.1.1\n",
            "intel-openmp                                      2025.1.1\n",
            "ipyevents                                         2.0.2\n",
            "ipyfilechooser                                    0.6.0\n",
            "ipykernel                                         6.17.1\n",
            "ipyleaflet                                        0.19.2\n",
            "ipyparallel                                       8.8.0\n",
            "ipython                                           7.34.0\n",
            "ipython-genutils                                  0.2.0\n",
            "ipython-sql                                       0.5.0\n",
            "ipytree                                           0.2.2\n",
            "ipywidgets                                        7.7.1\n",
            "ir_datasets                                       0.5.10\n",
            "itsdangerous                                      2.2.0\n",
            "jaraco.classes                                    3.4.0\n",
            "jaraco.context                                    6.0.1\n",
            "jaraco.functools                                  4.1.0\n",
            "jax                                               0.5.2\n",
            "jax-cuda12-pjrt                                   0.5.1\n",
            "jax-cuda12-plugin                                 0.5.1\n",
            "jaxlib                                            0.5.1\n",
            "jeepney                                           0.9.0\n",
            "jieba                                             0.42.1\n",
            "Jinja2                                            3.1.6\n",
            "jiter                                             0.10.0\n",
            "joblib                                            1.5.0\n",
            "jsonpatch                                         1.33\n",
            "jsonpickle                                        4.1.0\n",
            "jsonpointer                                       3.0.0\n",
            "jsonschema                                        4.23.0\n",
            "jsonschema-specifications                         2025.4.1\n",
            "jupyter-client                                    6.1.12\n",
            "jupyter-console                                   6.1.0\n",
            "jupyter_core                                      5.7.2\n",
            "jupyter_kernel_gateway                            2.5.2\n",
            "jupyter-leaflet                                   0.19.2\n",
            "jupyter-server                                    1.16.0\n",
            "jupyterlab_pygments                               0.3.0\n",
            "jupyterlab_widgets                                3.0.15\n",
            "kaggle                                            1.7.4.5\n",
            "kagglehub                                         0.3.12\n",
            "keras                                             3.8.0\n",
            "keras-hub                                         0.18.1\n",
            "keras-nlp                                         0.18.1\n",
            "keyring                                           25.6.0\n",
            "keyrings.google-artifactregistry-auth             1.1.2\n",
            "kiwisolver                                        1.4.8\n",
            "langchain                                         0.3.25\n",
            "langchain-core                                    0.3.60\n",
            "langchain-text-splitters                          0.3.8\n",
            "langcodes                                         3.5.0\n",
            "langsmith                                         0.3.42\n",
            "language_data                                     1.3.0\n",
            "launchpadlib                                      1.10.16\n",
            "lazr.restfulclient                                0.14.4\n",
            "lazr.uri                                          1.0.6\n",
            "lazy_loader                                       0.4\n",
            "libclang                                          18.1.1\n",
            "libcudf-cu12                                      25.2.1\n",
            "libcugraph-cu12                                   25.2.0\n",
            "libcuml-cu12                                      25.2.1\n",
            "libcuvs-cu12                                      25.2.1\n",
            "libkvikio-cu12                                    25.2.1\n",
            "libpysal                                          4.13.0\n",
            "libraft-cu12                                      25.2.0\n",
            "librosa                                           0.11.0\n",
            "libucx-cu12                                       1.18.1\n",
            "libucxx-cu12                                      0.42.0\n",
            "lightgbm                                          4.5.0\n",
            "linkify-it-py                                     2.0.3\n",
            "llama-cloud                                       0.1.21\n",
            "llama-cloud-services                              0.6.15\n",
            "llama_cpp_python                                  0.3.7\n",
            "llama-index                                       0.12.37\n",
            "llama-index-agent-openai                          0.4.8\n",
            "llama-index-cli                                   0.4.1\n",
            "llama-index-core                                  0.12.37\n",
            "llama-index-embeddings-huggingface                0.5.4\n",
            "llama-index-embeddings-openai                     0.3.1\n",
            "llama-index-indices-managed-llama-cloud           0.7.0\n",
            "llama-index-llms-llama-cpp                        0.4.0\n",
            "llama-index-llms-openai                           0.3.44\n",
            "llama-index-multi-modal-llms-openai               0.4.3\n",
            "llama-index-postprocessor-flag-embedding-reranker 0.3.0\n",
            "llama-index-program-openai                        0.3.1\n",
            "llama-index-question-gen-openai                   0.3.0\n",
            "llama-index-readers-file                          0.4.8\n",
            "llama-index-readers-llama-parse                   0.4.0\n",
            "llama-parse                                       0.6.12\n",
            "llvmlite                                          0.43.0\n",
            "locket                                            1.0.0\n",
            "logical-unification                               0.4.6\n",
            "lxml                                              5.4.0\n",
            "lz4                                               4.4.4\n",
            "Mako                                              1.1.3\n",
            "marisa-trie                                       1.2.1\n",
            "Markdown                                          3.8\n",
            "markdown-it-py                                    3.0.0\n",
            "MarkupSafe                                        3.0.2\n",
            "marshmallow                                       3.26.1\n",
            "matplotlib                                        3.10.0\n",
            "matplotlib-inline                                 0.1.7\n",
            "matplotlib-venn                                   1.1.2\n",
            "mdit-py-plugins                                   0.4.2\n",
            "mdurl                                             0.1.2\n",
            "miniKanren                                        1.0.3\n",
            "missingno                                         0.5.2\n",
            "mistune                                           3.1.3\n",
            "mizani                                            0.13.5\n",
            "mkl                                               2025.0.1\n",
            "ml-dtypes                                         0.4.1\n",
            "mlxtend                                           0.23.4\n",
            "more-itertools                                    10.7.0\n",
            "moviepy                                           1.0.3\n",
            "mpmath                                            1.3.0\n",
            "msgpack                                           1.1.0\n",
            "multidict                                         6.4.4\n",
            "multipledispatch                                  1.0.0\n",
            "multiprocess                                      0.70.15\n",
            "multitasking                                      0.0.11\n",
            "murmurhash                                        1.0.12\n",
            "music21                                           9.3.0\n",
            "mypy_extensions                                   1.1.0\n",
            "namex                                             0.0.9\n",
            "narwhals                                          1.40.0\n",
            "natsort                                           8.4.0\n",
            "nbclassic                                         1.3.1\n",
            "nbclient                                          0.10.2\n",
            "nbconvert                                         7.16.6\n",
            "nbformat                                          5.10.4\n",
            "ndindex                                           1.10.0\n",
            "nest-asyncio                                      1.6.0\n",
            "networkx                                          3.4.2\n",
            "nibabel                                           5.3.2\n",
            "nltk                                              3.9.1\n",
            "notebook                                          6.5.7\n",
            "notebook_shim                                     0.2.4\n",
            "numba                                             0.60.0\n",
            "numba-cuda                                        0.2.0\n",
            "numexpr                                           2.10.2\n",
            "numpy                                             1.26.4\n",
            "nvidia-cublas-cu12                                12.4.5.8\n",
            "nvidia-cuda-cupti-cu12                            12.4.127\n",
            "nvidia-cuda-nvcc-cu12                             12.5.82\n",
            "nvidia-cuda-nvrtc-cu12                            12.4.127\n",
            "nvidia-cuda-runtime-cu12                          12.4.127\n",
            "nvidia-cudnn-cu12                                 9.1.0.70\n",
            "nvidia-cufft-cu12                                 11.2.1.3\n",
            "nvidia-curand-cu12                                10.3.5.147\n",
            "nvidia-cusolver-cu12                              11.6.1.9\n",
            "nvidia-cusparse-cu12                              12.3.1.170\n",
            "nvidia-cusparselt-cu12                            0.6.2\n",
            "nvidia-ml-py                                      12.575.51\n",
            "nvidia-nccl-cu12                                  2.21.5\n",
            "nvidia-nvcomp-cu12                                4.2.0.11\n",
            "nvidia-nvjitlink-cu12                             12.4.127\n",
            "nvidia-nvtx-cu12                                  12.4.127\n",
            "nvtx                                              0.2.11\n",
            "nx-cugraph-cu12                                   25.2.0\n",
            "oauth2client                                      4.1.3\n",
            "oauthlib                                          3.2.2\n",
            "omegaconf                                         2.3.0\n",
            "openai                                            1.81.0\n",
            "opencv-contrib-python                             4.11.0.86\n",
            "opencv-python                                     4.11.0.86\n",
            "opencv-python-headless                            4.11.0.86\n",
            "openpyxl                                          3.1.5\n",
            "opt_einsum                                        3.4.0\n",
            "optax                                             0.2.4\n",
            "optree                                            0.15.0\n",
            "orbax-checkpoint                                  0.11.13\n",
            "orjson                                            3.10.18\n",
            "osqp                                              1.0.4\n",
            "packaging                                         24.2\n",
            "pandas                                            2.2.2\n",
            "pandas-datareader                                 0.10.0\n",
            "pandas-gbq                                        0.29.0\n",
            "pandas-stubs                                      2.2.2.240909\n",
            "pandocfilters                                     1.5.1\n",
            "panel                                             1.7.0\n",
            "param                                             2.2.0\n",
            "parso                                             0.8.4\n",
            "parsy                                             2.1\n",
            "partd                                             1.4.2\n",
            "pathlib                                           1.0.1\n",
            "patsy                                             1.0.1\n",
            "peewee                                            3.18.1\n",
            "peft                                              0.15.2\n",
            "pexpect                                           4.9.0\n",
            "pickleshare                                       0.7.5\n",
            "pillow                                            11.2.1\n",
            "pip                                               24.1.2\n",
            "platformdirs                                      4.3.8\n",
            "plotly                                            5.24.1\n",
            "plotnine                                          0.14.5\n",
            "pluggy                                            1.6.0\n",
            "ply                                               3.11\n",
            "polars                                            1.21.0\n",
            "pooch                                             1.8.2\n",
            "portpicker                                        1.5.2\n",
            "preshed                                           3.0.9\n",
            "prettytable                                       3.16.0\n",
            "proglog                                           0.1.12\n",
            "progressbar2                                      4.5.0\n",
            "prometheus_client                                 0.22.0\n",
            "promise                                           2.3\n",
            "prompt_toolkit                                    3.0.51\n",
            "propcache                                         0.3.1\n",
            "prophet                                           1.1.6\n",
            "proto-plus                                        1.26.1\n",
            "protobuf                                          5.29.4\n",
            "psutil                                            5.9.5\n",
            "psycopg2                                          2.9.10\n",
            "ptyprocess                                        0.7.0\n",
            "py-cpuinfo                                        9.0.0\n",
            "py4j                                              0.10.9.7\n",
            "pyarrow                                           18.1.0\n",
            "pyasn1                                            0.6.1\n",
            "pyasn1_modules                                    0.4.2\n",
            "pycairo                                           1.28.0\n",
            "pycocotools                                       2.0.8\n",
            "pycparser                                         2.22\n",
            "pycryptodomex                                     3.23.0\n",
            "pydantic                                          2.11.4\n",
            "pydantic_core                                     2.33.2\n",
            "pydata-google-auth                                1.9.1\n",
            "pydot                                             3.0.4\n",
            "pydotplus                                         2.0.2\n",
            "PyDrive                                           1.3.1\n",
            "PyDrive2                                          1.21.3\n",
            "pyerfa                                            2.0.1.5\n",
            "pygame                                            2.6.1\n",
            "pygit2                                            1.18.0\n",
            "Pygments                                          2.19.1\n",
            "PyGObject                                         3.42.0\n",
            "PyJWT                                             2.10.1\n",
            "pylibcudf-cu12                                    25.2.1\n",
            "pylibcugraph-cu12                                 25.2.0\n",
            "pylibraft-cu12                                    25.2.0\n",
            "pymc                                              5.22.0\n",
            "pymystem3                                         0.2.0\n",
            "pynndescent                                       0.5.13\n",
            "pynvjitlink-cu12                                  0.6.0\n",
            "pynvml                                            12.0.0\n",
            "pyogrio                                           0.11.0\n",
            "pyomo                                             6.9.2\n",
            "PyOpenGL                                          3.1.9\n",
            "pyOpenSSL                                         24.2.1\n",
            "pyparsing                                         3.2.3\n",
            "pypdf                                             5.5.0\n",
            "pyperclip                                         1.9.0\n",
            "pyproj                                            3.7.1\n",
            "pyproject_hooks                                   1.2.0\n",
            "pyshp                                             2.3.1\n",
            "PySocks                                           1.7.1\n",
            "pyspark                                           3.5.1\n",
            "pytensor                                          2.30.3\n",
            "pytest                                            8.3.5\n",
            "python-apt                                        0.0.0\n",
            "python-box                                        7.3.2\n",
            "python-dateutil                                   2.9.0.post0\n",
            "python-dotenv                                     1.1.0\n",
            "python-louvain                                    0.16\n",
            "python-slugify                                    8.0.4\n",
            "python-snappy                                     0.7.3\n",
            "python-utils                                      3.9.1\n",
            "pytz                                              2025.2\n",
            "pyviz_comms                                       3.0.4\n",
            "PyWavelets                                        1.8.0\n",
            "PyYAML                                            6.0.2\n",
            "pyzmq                                             24.0.1\n",
            "raft-dask-cu12                                    25.2.0\n",
            "rapids-dask-dependency                            25.2.0\n",
            "ratelim                                           0.1.6\n",
            "referencing                                       0.36.2\n",
            "regex                                             2024.11.6\n",
            "requests                                          2.32.3\n",
            "requests-oauthlib                                 2.0.0\n",
            "requests-toolbelt                                 1.0.0\n",
            "requirements-parser                               0.9.0\n",
            "rich                                              13.9.4\n",
            "rmm-cu12                                          25.2.0\n",
            "roman-numerals-py                                 3.1.0\n",
            "rpds-py                                           0.25.1\n",
            "rpy2                                              3.5.17\n",
            "rsa                                               4.9.1\n",
            "safetensors                                       0.5.3\n",
            "scikit-image                                      0.25.2\n",
            "scikit-learn                                      1.6.1\n",
            "scipy                                             1.15.3\n",
            "scooby                                            0.10.1\n",
            "scs                                               3.2.7.post2\n",
            "seaborn                                           0.13.2\n",
            "SecretStorage                                     3.3.3\n",
            "Send2Trash                                        1.8.3\n",
            "sentence-transformers                             4.1.0\n",
            "sentencepiece                                     0.2.0\n",
            "sentry-sdk                                        2.29.1\n",
            "setproctitle                                      1.3.6\n",
            "setuptools                                        75.2.0\n",
            "shap                                              0.47.2\n",
            "shapely                                           2.1.1\n",
            "shellingham                                       1.5.4\n",
            "simple-parsing                                    0.1.7\n",
            "simplejson                                        3.20.1\n",
            "simsimd                                           6.2.1\n",
            "six                                               1.17.0\n",
            "sklearn-compat                                    0.1.3\n",
            "sklearn-pandas                                    2.2.0\n",
            "slicer                                            0.0.8\n",
            "smart-open                                        7.1.0\n",
            "smmap                                             5.0.2\n",
            "sniffio                                           1.3.1\n",
            "snowballstemmer                                   3.0.1\n",
            "sortedcontainers                                  2.4.0\n",
            "soundfile                                         0.13.1\n",
            "soupsieve                                         2.7\n",
            "soxr                                              0.5.0.post1\n",
            "spacy                                             3.8.6\n",
            "spacy-legacy                                      3.0.12\n",
            "spacy-loggers                                     1.0.5\n",
            "spanner-graph-notebook                            1.1.6\n",
            "Sphinx                                            8.2.3\n",
            "sphinxcontrib-applehelp                           2.0.0\n",
            "sphinxcontrib-devhelp                             2.0.0\n",
            "sphinxcontrib-htmlhelp                            2.1.0\n",
            "sphinxcontrib-jsmath                              1.0.1\n",
            "sphinxcontrib-qthelp                              2.0.0\n",
            "sphinxcontrib-serializinghtml                     2.0.0\n",
            "SQLAlchemy                                        2.0.41\n",
            "sqlglot                                           25.20.2\n",
            "sqlparse                                          0.5.3\n",
            "srsly                                             2.5.1\n",
            "stanio                                            0.5.1\n",
            "statsmodels                                       0.14.4\n",
            "stringzilla                                       3.12.5\n",
            "striprtf                                          0.0.26\n",
            "stumpy                                            1.13.0\n",
            "sympy                                             1.13.1\n",
            "tables                                            3.10.2\n",
            "tabulate                                          0.9.0\n",
            "tbb                                               2022.1.0\n",
            "tblib                                             3.1.0\n",
            "tcmlib                                            1.3.0\n",
            "tenacity                                          9.1.2\n",
            "tensorboard                                       2.18.0\n",
            "tensorboard-data-server                           0.7.2\n",
            "tensorflow                                        2.18.0\n",
            "tensorflow-datasets                               4.9.8\n",
            "tensorflow_decision_forests                       1.11.0\n",
            "tensorflow-hub                                    0.16.1\n",
            "tensorflow-io-gcs-filesystem                      0.37.1\n",
            "tensorflow-metadata                               1.17.1\n",
            "tensorflow-probability                            0.25.0\n",
            "tensorflow-text                                   2.18.1\n",
            "tensorstore                                       0.1.74\n",
            "termcolor                                         3.1.0\n",
            "terminado                                         0.18.1\n",
            "text-unidecode                                    1.3\n",
            "textblob                                          0.19.0\n",
            "tf_keras                                          2.18.0\n",
            "tf-slim                                           1.1.0\n",
            "thinc                                             8.3.6\n",
            "threadpoolctl                                     3.6.0\n",
            "tifffile                                          2025.5.21\n",
            "tiktoken                                          0.9.0\n",
            "timm                                              1.0.15\n",
            "tinycss2                                          1.4.0\n",
            "tokenizers                                        0.21.1\n",
            "toml                                              0.10.2\n",
            "toolz                                             0.12.1\n",
            "torch                                             2.6.0+cu124\n",
            "torchao                                           0.10.0\n",
            "torchaudio                                        2.6.0+cu124\n",
            "torchdata                                         0.11.0\n",
            "torchsummary                                      1.5.1\n",
            "torchtune                                         0.6.1\n",
            "torchvision                                       0.21.0+cu124\n",
            "tornado                                           6.4.2\n",
            "tqdm                                              4.67.1\n",
            "traitlets                                         5.7.1\n",
            "traittypes                                        0.2.1\n",
            "transformers                                      4.52.2\n",
            "trec-car-tools                                    2.6\n",
            "treelite                                          4.4.1\n",
            "treescope                                         0.1.9\n",
            "triton                                            3.2.0\n",
            "tsfresh                                           0.21.0\n",
            "tweepy                                            4.15.0\n",
            "typeguard                                         4.4.2\n",
            "typer                                             0.15.3\n",
            "types-pytz                                        2025.2.0.20250516\n",
            "types-setuptools                                  80.8.0.20250521\n",
            "typing_extensions                                 4.13.2\n",
            "typing-inspect                                    0.9.0\n",
            "typing-inspection                                 0.4.1\n",
            "tzdata                                            2025.2\n",
            "tzlocal                                           5.3.1\n",
            "uc-micro-py                                       1.0.3\n",
            "ucx-py-cu12                                       0.42.0\n",
            "ucxx-cu12                                         0.42.0\n",
            "umap-learn                                        0.5.7\n",
            "umf                                               0.10.0\n",
            "unlzw3                                            0.2.3\n",
            "uritemplate                                       4.1.1\n",
            "urllib3                                           2.4.0\n",
            "vega-datasets                                     0.9.0\n",
            "wadllib                                           1.3.6\n",
            "wandb                                             0.19.11\n",
            "warc3-wet                                         0.2.5\n",
            "warc3-wet-clueweb09                               0.2.5\n",
            "wasabi                                            1.1.3\n",
            "wcwidth                                           0.2.13\n",
            "weasel                                            0.4.1\n",
            "webcolors                                         24.11.1\n",
            "webencodings                                      0.5.1\n",
            "websocket-client                                  1.8.0\n",
            "websockets                                        15.0.1\n",
            "Werkzeug                                          3.1.3\n",
            "wheel                                             0.45.1\n",
            "widgetsnbextension                                3.6.10\n",
            "wordcloud                                         1.9.4\n",
            "wrapt                                             1.17.2\n",
            "wurlitzer                                         3.1.1\n",
            "xarray                                            2025.3.1\n",
            "xarray-einstats                                   0.8.0\n",
            "xgboost                                           2.1.4\n",
            "xlrd                                              2.0.1\n",
            "xxhash                                            3.5.0\n",
            "xyzservices                                       2025.4.0\n",
            "yarl                                              1.20.0\n",
            "ydf                                               0.12.0\n",
            "yellowbrick                                       1.5\n",
            "yfinance                                          0.2.61\n",
            "zict                                              3.0.0\n",
            "zipp                                              3.21.0\n",
            "zlib-state                                        0.1.9\n",
            "zstandard                                         0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "8fvwyTsP0M52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f5a67417-cb0f-4ee8-b831-90a469db05da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!CMAKE_ARGS=\"-DGGML_CUDA=on\" pip install llama-cpp-python==0.3.7 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu125 --upgrade --force-reinstall --no-cache-dir"
      ],
      "metadata": {
        "id": "19-qcaXIQ0bI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "ff9eb85e-8737-42da-da45-061647a05593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://abetlen.github.io/llama-cpp-python/whl/cu125\n",
            "Collecting llama-cpp-python==0.3.7\n",
            "  Downloading llama_cpp_python-0.3.7.tar.gz (66.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting typing-extensions>=4.5.0 (from llama-cpp-python==0.3.7)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting numpy>=1.20.0 (from llama-cpp-python==0.3.7)\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m266.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache>=5.6.1 (from llama-cpp-python==0.3.7)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting jinja2>=2.11.3 (from llama-cpp-python==0.3.7)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python==0.3.7)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m218.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m331.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m338.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m231.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.7-cp311-cp311-linux_x86_64.whl size=41082200 sha256=76ab6a3c2877cca81216684e5ca04020522db1388cd0c0252bf447bcd8032db7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9_qa511s/wheels/eb/82/79/ac77fcd49324b75ae6aa18e63a87cf9da4371a57e2cdc8dc03\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: typing-extensions, numpy, MarkupSafe, diskcache, jinja2, llama-cpp-python\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: diskcache\n",
            "    Found existing installation: diskcache 5.6.3\n",
            "    Uninstalling diskcache-5.6.3:\n",
            "      Successfully uninstalled diskcache-5.6.3\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: llama-cpp-python\n",
            "    Found existing installation: llama_cpp_python 0.3.7\n",
            "    Uninstalling llama_cpp_python-0.3.7:\n",
            "      Successfully uninstalled llama_cpp_python-0.3.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 diskcache-5.6.3 jinja2-3.1.6 llama-cpp-python-0.3.7 numpy-2.2.6 typing-extensions-4.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install numpy==1.26.4\n",
        "!pip install numpy==1.26.4 --force-reinstall --no-cache-dir"
      ],
      "metadata": {
        "id": "TtlNJadoUF5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6ed9c24-e632-4167-a499-8f5b7d9ff608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m336.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.6\n",
            "    Uninstalling numpy-2.2.6:\n",
            "      Successfully uninstalled numpy-2.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2UAfS56lZh-"
      },
      "source": [
        "## Implementation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "WluguhYZVhAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b6d1663-e81c-4b21-9e54-c16d8f88338a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GGPMIiOpF4b"
      },
      "source": [
        "## Load documents and build index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0hb-49phJj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "850598f3-e8c8-42c1-d329-5257d845219c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 11min 35s, sys: 6.1 s, total: 11min 41s\n",
            "Wall time: 11min 40s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3039"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "%%time\n",
        "documents = SimpleDirectoryReader(\"/content/drive/MyDrive/Courses/RAG/SDD\").load_data()\n",
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5czlXaU6gPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df9f352-2ba3-47f1-f6de-e3c0740cd683"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'page_label': '1',\n",
              " 'file_name': '537 Guide for Transformer Fire Safety Practices.pdf',\n",
              " 'file_path': '/content/drive/MyDrive/Courses/RAG/SDD/537 Guide for Transformer Fire Safety Practices.pdf',\n",
              " 'file_type': 'application/pdf',\n",
              " 'file_size': 4172940,\n",
              " 'creation_date': '2025-05-28',\n",
              " 'last_modified_date': '2018-02-14'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "documents[0].metadata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents[100]"
      ],
      "metadata": {
        "id": "e04jw1eRuLht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a50f69-2c9b-4575-c29a-63381eee9910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(id_='0b517d5d-fc66-40c7-bc0b-df769f891e67', embedding=None, metadata={'page_label': '101', 'file_name': '537 Guide for Transformer Fire Safety Practices.pdf', 'file_path': '/content/drive/MyDrive/Courses/RAG/SDD/537 Guide for Transformer Fire Safety Practices.pdf', 'file_type': 'application/pdf', 'file_size': 4172940, 'creation_date': '2025-05-28', 'last_modified_date': '2018-02-14'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Guide for Transformer Fire Safety Practices\\n92\\nFigure 42 illustrates how a fire barrier is used to protect two adjacent transformers. FM Global\\nadvises that the fire wall should ex tend at least 600mm horizontally and 300 mm vertically beyond\\nany transformer component that could be pressurized as a result of an electrical fault, including oil\\nfilled bushings. This is represented by the distance “d” and “e” respectively.\\nElevation view Plan view\\nFigure 42: Fire Barrier protecting two adjacent transformers.\\nd d\\ne\\nd d\\ne\\n2 Hour rated Fire Barrier\\nTransformer\\nContainment\\n2 Hour rated Fire Barrier\\n2 Hour rated Fire Barrier', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Llama3.1 8B 4bit GGUF ( 4.92 GB. )\n",
        "\n",
        "https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF"
      ],
      "metadata": {
        "id": "aqUERS2wsLx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def messages_to_prompt(messages):\n",
        "    prompt = \"\"\n",
        "    for message in messages:\n",
        "        if message.role == 'system':\n",
        "          prompt += f\"<|start_header_id|>system<|end_header_id|>{message.content}<|eot_id|>\\n\"\n",
        "          #prompt += f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>{message.content}<|eot_id|>\\n\"\n",
        "        elif message.role == 'user':\n",
        "          prompt += f\"<|start_header_id|>user<|end_header_id|>{message.content}<|eot_id|>\\n\"\n",
        "        elif message.role == 'assistant':\n",
        "          prompt += f\"<|start_header_id|>assistant<|end_header_id|>{message.content}<|eot_id|>\\n\"\n",
        "\n",
        "    # ensure we start with a system prompt, insert blank if needed\n",
        "    # if not prompt.startswith(\"<|begin_of_text|><|start_header_id|>system\"):\n",
        "    #     prompt = \"<|begin_of_text|>\" + prompt\n",
        "\n",
        "    # add final assistant prompt\n",
        "    prompt = prompt + \"<|start_header_id|>assistant<|end_header_id|><|eot_id|>\\n\"\n",
        "    return prompt\n",
        "\n",
        "def completion_to_prompt(completion):\n",
        "    return f\"<|start_header_id|>system<|end_header_id|><|eot_id|>\\n<|start_header_id|>user<|end_header_id|>{completion}<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
        "    #return f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|><|eot_id|>\\n<|start_header_id|>user<|end_header_id|>{completion}<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n\""
      ],
      "metadata": {
        "id": "sRpJ2bQczvOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ลิงก์จาก repo ใน huggingface\n",
        "model_url = \"https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf\"\n",
        "#model_url = 'https://huggingface.co/lmstudio-community/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q8_0.gguf'\n",
        "#model_url = 'https://huggingface.co/lmstudio-community/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_M.gguf'\n",
        "\n",
        "# From Google Drive\n",
        "#model_path = '/content/drive/MyDrive/BaseModel/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf'\n",
        "\n",
        "from llama_index.llms.llama_cpp import LlamaCPP\n",
        "\n",
        "llm = LlamaCPP(\n",
        "    model_url=model_url,\n",
        "    model_path=None,\n",
        "    temperature=0.1,\n",
        "    context_window=8192,\n",
        "    max_new_tokens=1024, # อาจจะตอบเพิ่มออกมาอีก 1024 bytes\n",
        "    generate_kwargs={},\n",
        "    model_kwargs={\n",
        "        \"repetition-penalty\":1.4,\n",
        "        \"no_repeat_ngram_size\": 4,\n",
        "         #\"response_format\": { \"type\": \"json_object\" },\n",
        "        \"n_gpu_layers\": -1\n",
        "        },\n",
        "    #model_kwargs={\"n_gpu_layers\": 33},\n",
        "    messages_to_prompt=messages_to_prompt,\n",
        "    completion_to_prompt=completion_to_prompt,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "mS0R2fsLlBYl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e23b158-67de-4aea-c835-784cf1767a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
            "ggml_cuda_init: found 1 CUDA devices:\n",
            "  Device 0: NVIDIA L4, compute capability 8.9, VMM: yes\n",
            "llama_model_load_from_file_impl: using device CUDA0 (NVIDIA L4) - 22503 MiB free\n",
            "llama_model_loader: loaded meta data with 33 key-value pairs and 292 tensors from /tmp/llama_index/models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Meta Llama 3.1 8B Instruct\n",
            "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
            "llama_model_loader: - kv   4:                           general.basename str              = Meta-Llama-3.1\n",
            "llama_model_loader: - kv   5:                         general.size_label str              = 8B\n",
            "llama_model_loader: - kv   6:                            general.license str              = llama3.1\n",
            "llama_model_loader: - kv   7:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
            "llama_model_loader: - kv   8:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\n",
            "llama_model_loader: - kv   9:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv  10:                       llama.context_length u32              = 131072\n",
            "llama_model_loader: - kv  11:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  17:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009\n",
            "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
            "llama_model_loader: - kv  28:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  29:                      quantize.imatrix.file str              = /models_out/Meta-Llama-3.1-8B-Instruc...\n",
            "llama_model_loader: - kv  30:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
            "llama_model_loader: - kv  31:             quantize.imatrix.entries_count i32              = 224\n",
            "llama_model_loader: - kv  32:              quantize.imatrix.chunks_count i32              = 125\n",
            "llama_model_loader: - type  f32:   66 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 4.58 GiB (4.89 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 2\n",
            "load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
            "load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
            "load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
            "load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
            "load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
            "load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
            "load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
            "load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
            "load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
            "load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
            "load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
            "load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
            "load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
            "load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
            "load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
            "load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
            "load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
            "load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
            "load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
            "load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
            "load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
            "load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
            "load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
            "load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
            "load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
            "load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
            "load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
            "load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
            "load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
            "load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
            "load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
            "load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
            "load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
            "load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
            "load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
            "load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
            "load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
            "load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
            "load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
            "load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
            "load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
            "load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
            "load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
            "load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
            "load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
            "load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
            "load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
            "load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
            "load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
            "load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
            "load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
            "load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
            "load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
            "load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
            "load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
            "load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
            "load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
            "load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
            "load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
            "load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
            "load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
            "load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
            "load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
            "load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
            "load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
            "load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
            "load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
            "load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
            "load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
            "load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
            "load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
            "load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
            "load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
            "load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
            "load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
            "load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
            "load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
            "load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
            "load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
            "load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
            "load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
            "load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
            "load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
            "load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
            "load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
            "load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
            "load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
            "load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
            "load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
            "load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
            "load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
            "load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
            "load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
            "load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
            "load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
            "load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
            "load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
            "load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
            "load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
            "load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
            "load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
            "load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
            "load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
            "load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
            "load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
            "load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
            "load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
            "load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
            "load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
            "load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
            "load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
            "load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
            "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
            "load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
            "load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
            "load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
            "load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
            "load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
            "load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
            "load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
            "load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
            "load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
            "load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
            "load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
            "load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
            "load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
            "load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
            "load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
            "load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
            "load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
            "load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
            "load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
            "load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
            "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
            "load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
            "load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
            "load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
            "load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
            "load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
            "load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
            "load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
            "load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
            "load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
            "load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
            "load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
            "load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
            "load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
            "load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
            "load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
            "load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
            "load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
            "load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
            "load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
            "load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
            "load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
            "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
            "load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
            "load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
            "load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
            "load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
            "load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
            "load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
            "load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
            "load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
            "load: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
            "load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
            "load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
            "load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
            "load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
            "load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
            "load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
            "load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
            "load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
            "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
            "load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
            "load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
            "load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
            "load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
            "load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
            "load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
            "load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
            "load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
            "load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
            "load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
            "load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
            "load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
            "load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
            "load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
            "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
            "load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
            "load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
            "load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
            "load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
            "load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
            "load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
            "load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
            "load: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
            "load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
            "load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
            "load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
            "load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
            "load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
            "load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
            "load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
            "load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
            "load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
            "load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
            "load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
            "load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
            "load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
            "load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
            "load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
            "load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
            "load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
            "load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
            "load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
            "load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
            "load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
            "load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
            "load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
            "load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
            "load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
            "load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
            "load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
            "load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
            "load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
            "load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
            "load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
            "load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
            "load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
            "load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
            "load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
            "load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
            "load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
            "load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
            "load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
            "load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
            "load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
            "load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
            "load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
            "load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
            "load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
            "load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
            "load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
            "load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
            "load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
            "load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
            "load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
            "load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
            "load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
            "load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
            "load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
            "load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
            "load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
            "load: special tokens cache size = 256\n",
            "load: token to piece cache size = 0.7999 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 131072\n",
            "print_info: n_embd           = 4096\n",
            "print_info: n_layer          = 32\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 4\n",
            "print_info: n_embd_k_gqa     = 1024\n",
            "print_info: n_embd_v_gqa     = 1024\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: n_ff             = 14336\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 500000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 131072\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: ssm_d_conv       = 0\n",
            "print_info: ssm_d_inner      = 0\n",
            "print_info: ssm_d_state      = 0\n",
            "print_info: ssm_dt_rank      = 0\n",
            "print_info: ssm_dt_b_c_rms   = 0\n",
            "print_info: model type       = 8B\n",
            "print_info: model params     = 8.03 B\n",
            "print_info: general.name     = Meta Llama 3.1 8B Instruct\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 128256\n",
            "print_info: n_merges         = 280147\n",
            "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
            "print_info: EOS token        = 128009 '<|eot_id|>'\n",
            "print_info: EOT token        = 128009 '<|eot_id|>'\n",
            "print_info: EOM token        = 128008 '<|eom_id|>'\n",
            "print_info: LF token         = 128 'Ä'\n",
            "print_info: EOG token        = 128008 '<|eom_id|>'\n",
            "print_info: EOG token        = 128009 '<|eot_id|>'\n",
            "print_info: max token length = 256\n",
            "load_tensors: layer   0 assigned to device CUDA0\n",
            "load_tensors: layer   1 assigned to device CUDA0\n",
            "load_tensors: layer   2 assigned to device CUDA0\n",
            "load_tensors: layer   3 assigned to device CUDA0\n",
            "load_tensors: layer   4 assigned to device CUDA0\n",
            "load_tensors: layer   5 assigned to device CUDA0\n",
            "load_tensors: layer   6 assigned to device CUDA0\n",
            "load_tensors: layer   7 assigned to device CUDA0\n",
            "load_tensors: layer   8 assigned to device CUDA0\n",
            "load_tensors: layer   9 assigned to device CUDA0\n",
            "load_tensors: layer  10 assigned to device CUDA0\n",
            "load_tensors: layer  11 assigned to device CUDA0\n",
            "load_tensors: layer  12 assigned to device CUDA0\n",
            "load_tensors: layer  13 assigned to device CUDA0\n",
            "load_tensors: layer  14 assigned to device CUDA0\n",
            "load_tensors: layer  15 assigned to device CUDA0\n",
            "load_tensors: layer  16 assigned to device CUDA0\n",
            "load_tensors: layer  17 assigned to device CUDA0\n",
            "load_tensors: layer  18 assigned to device CUDA0\n",
            "load_tensors: layer  19 assigned to device CUDA0\n",
            "load_tensors: layer  20 assigned to device CUDA0\n",
            "load_tensors: layer  21 assigned to device CUDA0\n",
            "load_tensors: layer  22 assigned to device CUDA0\n",
            "load_tensors: layer  23 assigned to device CUDA0\n",
            "load_tensors: layer  24 assigned to device CUDA0\n",
            "load_tensors: layer  25 assigned to device CUDA0\n",
            "load_tensors: layer  26 assigned to device CUDA0\n",
            "load_tensors: layer  27 assigned to device CUDA0\n",
            "load_tensors: layer  28 assigned to device CUDA0\n",
            "load_tensors: layer  29 assigned to device CUDA0\n",
            "load_tensors: layer  30 assigned to device CUDA0\n",
            "load_tensors: layer  31 assigned to device CUDA0\n",
            "load_tensors: layer  32 assigned to device CUDA0\n",
            "load_tensors: tensor 'token_embd.weight' (q4_K) (and 0 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
            "load_tensors: offloading 32 repeating layers to GPU\n",
            "load_tensors: offloading output layer to GPU\n",
            "load_tensors: offloaded 33/33 layers to GPU\n",
            "load_tensors:        CUDA0 model buffer size =  4403.49 MiB\n",
            "load_tensors:   CPU_Mapped model buffer size =   281.81 MiB\n",
            "llama_init_from_model: n_seq_max     = 1\n",
            "llama_init_from_model: n_ctx         = 8192\n",
            "llama_init_from_model: n_ctx_per_seq = 8192\n",
            "llama_init_from_model: n_batch       = 512\n",
            "llama_init_from_model: n_ubatch      = 512\n",
            "llama_init_from_model: flash_attn    = 0\n",
            "llama_init_from_model: freq_base     = 500000.0\n",
            "llama_init_from_model: freq_scale    = 1\n",
            "llama_init_from_model: n_ctx_per_seq (8192) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "llama_kv_cache_init: kv_size = 8192, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
            "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =  1024.00 MiB\n",
            "llama_init_from_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
            "llama_init_from_model:  CUDA_Host  output buffer size =     0.49 MiB\n",
            "llama_init_from_model:      CUDA0 compute buffer size =   560.00 MiB\n",
            "llama_init_from_model:  CUDA_Host compute buffer size =    24.01 MiB\n",
            "llama_init_from_model: graph nodes  = 1030\n",
            "llama_init_from_model: graph splits = 2\n",
            "CUDA : ARCHS = 890 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | AVX512 = 1 | AVX512_VNNI = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "Model metadata: {'quantize.imatrix.entries_count': '224', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'quantize.imatrix.chunks_count': '125', 'quantize.imatrix.file': '/models_out/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct.imatrix', 'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- set date_string = \"26 Jul 2024\" %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if builtin_tools is defined or tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{- \"Tools: \" + builtin_tools | reject(\\'equalto\\', \\'code_interpreter\\') | join(\", \") + \"\\\\n\\\\n\"}}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\\n                {{- arg_name + \\'=\"\\' + arg_val + \\'\"\\' }}\\n                {%- if not loop.last %}\\n                    {{- \", \" }}\\n                {%- endif %}\\n                {%- endfor %}\\n            {{- \")\" }}\\n        {%- else  %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n            {{- \\'\"parameters\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \"}\" }}\\n        {%- endif %}\\n        {%- if builtin_tools is defined %}\\n            {#- This means we\\'re in ipython mode #}\\n            {{- \"<|eom_id|>\" }}\\n        {%- else %}\\n            {{- \"<|eot_id|>\" }}\\n        {%- endif %}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '15', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '500000.000000', 'general.architecture': 'llama', 'general.basename': 'Meta-Llama-3.1', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Meta Llama 3.1 8B Instruct', 'general.finetune': 'Instruct', 'general.type': 'model', 'general.size_label': '8B', 'general.license': 'llama3.1', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8'}\n",
            "Available chat formats from metadata: chat_template.default\n",
            "Using gguf chat template: {{- bos_token }}\n",
            "{%- if custom_tools is defined %}\n",
            "    {%- set tools = custom_tools %}\n",
            "{%- endif %}\n",
            "{%- if not tools_in_user_message is defined %}\n",
            "    {%- set tools_in_user_message = true %}\n",
            "{%- endif %}\n",
            "{%- if not date_string is defined %}\n",
            "    {%- set date_string = \"26 Jul 2024\" %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
            "{%- if messages[0]['role'] == 'system' %}\n",
            "    {%- set system_message = messages[0]['content']|trim %}\n",
            "    {%- set messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set system_message = \"\" %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- System message + builtin tools #}\n",
            "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
            "{%- if builtin_tools is defined or tools is not none %}\n",
            "    {{- \"Environment: ipython\\n\" }}\n",
            "{%- endif %}\n",
            "{%- if builtin_tools is defined %}\n",
            "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n",
            "{%- endif %}\n",
            "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
            "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
            "{%- if tools is not none and not tools_in_user_message %}\n",
            "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\\n\\n\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\\n\\n\" }}\n",
            "    {%- endfor %}\n",
            "{%- endif %}\n",
            "{{- system_message }}\n",
            "{{- \"<|eot_id|>\" }}\n",
            "\n",
            "{#- Custom tools are passed in a user message with some extra guidance #}\n",
            "{%- if tools_in_user_message and not tools is none %}\n",
            "    {#- Extract the first user message so we can plug it in here #}\n",
            "    {%- if messages | length != 0 %}\n",
            "        {%- set first_user_message = messages[0]['content']|trim %}\n",
            "        {%- set messages = messages[1:] %}\n",
            "    {%- else %}\n",
            "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
            "{%- endif %}\n",
            "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
            "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
            "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\\n\\n\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\\n\\n\" }}\n",
            "    {%- endfor %}\n",
            "    {{- first_user_message + \"<|eot_id|>\"}}\n",
            "{%- endif %}\n",
            "\n",
            "{%- for message in messages %}\n",
            "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
            "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
            "    {%- elif 'tool_calls' in message %}\n",
            "        {%- if not message.tool_calls|length == 1 %}\n",
            "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
            "        {%- endif %}\n",
            "        {%- set tool_call = message.tool_calls[0].function %}\n",
            "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
            "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
            "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
            "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
            "                {%- if not loop.last %}\n",
            "                    {{- \", \" }}\n",
            "                {%- endif %}\n",
            "                {%- endfor %}\n",
            "            {{- \")\" }}\n",
            "        {%- else  %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
            "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
            "            {{- '\"parameters\": ' }}\n",
            "            {{- tool_call.arguments | tojson }}\n",
            "            {{- \"}\" }}\n",
            "        {%- endif %}\n",
            "        {%- if builtin_tools is defined %}\n",
            "            {#- This means we're in ipython mode #}\n",
            "            {{- \"<|eom_id|>\" }}\n",
            "        {%- else %}\n",
            "            {{- \"<|eot_id|>\" }}\n",
            "        {%- endif %}\n",
            "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
            "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
            "        {%- if message.content is mapping or message.content is iterable %}\n",
            "            {{- message.content | tojson }}\n",
            "        {%- else %}\n",
            "            {{- message.content }}\n",
            "        {%- endif %}\n",
            "        {{- \"<|eot_id|>\" }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "{%- if add_generation_prompt %}\n",
            "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
            "{%- endif %}\n",
            "\n",
            "Using chat eos_token: <|eot_id|>\n",
            "Using chat bos_token: <|begin_of_text|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm"
      ],
      "metadata": {
        "id": "p5XDCFomQDyG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dddd935-0803-432c-e155-ee6c30ad2c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaCPP(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7efebbd01710>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x7efebce63ec0>, completion_to_prompt=<function completion_to_prompt at 0x7efebce60180>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, model_url='https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf', model_path='/tmp/llama_index/models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf', temperature=0.1, max_new_tokens=1024, context_window=8192, generate_kwargs={'temperature': 0.1, 'max_tokens': 1024}, model_kwargs={'n_ctx': 8192, 'verbose': True, 'repetition-penalty': 1.4, 'no_repeat_ngram_size': 4, 'n_gpu_layers': -1}, verbose=True)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Model ( without RAG )"
      ],
      "metadata": {
        "id": "03Z2pdPhEP1O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMsRrw9s91wW"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# llm.generate_kwargs={'temperature': 0.1, 'max_tokens': 512}\n",
        "\n",
        "# response = llm.complete(\"กามโยคะ ภวโยคะ ทิฏฐิโยคะ และอวิชชาโยคะ\" )\n",
        "# display(Markdown(f\"{response.text}\"))\n",
        "# len(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "llm.generate_kwargs={'temperature': 0.1, 'max_tokens': 1024}\n",
        "stream_response = llm.stream_complete(\n",
        "    \"กามโยคะ ภวโยคะ ทิฏฐิโยคะ และอวิชชาโยคะ\"\n",
        ")\n",
        "for t in stream_response:\n",
        "    print(t.delta, end=\"\")\n",
        "print()"
      ],
      "metadata": {
        "id": "O6E0hCwpRNEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e38d3f0b-1202-4673-ed26-18b491ddeea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "โยคะ เป็นศิลปะการฝึกตนและฝึกสมาธิเพื่อสุขภาพและความสมดุลทางกายและจิต โดยมีหลายประเภท เช่น\n",
            "\n",
            "1. กามโยคะ (Hatha Yoga) - ศิลปะการฝึกตนเพื่อสุขภาพและความสมดุลทางกาย โดยใช้เทคนิคการยืดเหยียดและการหายใจลึก\n",
            "\n",
            "2. ภวโยคะ (Bhakti Yoga) - ศิลปะการฝึกตนเพื่อความเชื่อมั่นและความภักดี โดยใช้เทคนิคการฝึกสมาธิและการสักการะ\n",
            "\n",
            "3. ทิฏฐิโยคะ (Jnana Yoga) - ศิลปะการฝึกตนเพื่อความเข้าใจและความเห็นใจ โดยใช้เทคนิคการฝึกสมาธิและการสังเกต\n",
            "\n",
            "4. อวิชชาโยคะ (Kundalini Yoga) - ศิลปะการฝึกตนเพื่อการปลดปล่อยพลังภายใน โดยใช้เทคนิคการฝึกสมาธิและการหายใจลึก\n",
            "\n",
            "5. ราชนโยคะ (Raja Yoga) - ศิลปะการฝึกตนเพื่อการปลดปล่อยจิตวิญญาณ โดยใช้เทคนิคการฝึกสมาธิและการสังเกต\n",
            "\n",
            "6. คาร์นโยคะ (Karma Yoga) - ศิลปะการฝึกตนเพื่อการปลดปล่อยจิตวิญญาณ โดยใช้เทคนิคการฝึกสมาธิและการทำความดี\n",
            "\n",
            "7. นิมิตโยคะ (Mantra Yoga) - ศิลปะการฝึกตนเพื่อการปลดปล่อยจิตวิญญาณ โดยใช้เทคนิคการฝึกสมาธิและการใช้คำสอน\n",
            "\n",
            "8. ลัทธิโยคะ (Laya Yoga) - ศิลปะการฝึกตนเพื่อการปลดปล่อยจิตวิญญาณ โดยใช้เทคนิคการฝึกสมาธิและการหายใจลึก\n",
            "\n",
            "9. นาธโยคะ (Natha Yoga) - ศิลปะการฝึกตนเพื่อการปลดปล่อยจิตวิญญาณ โดยใช้เทคนิคการฝึกสมาธิและการสังเกต\n",
            "\n",
            "10. วิชนูโยคะ (Vijnana Yoga) - ศิลปะการฝึกตนเพื่อการปลดปล่อยจิตวิญญาณ โดยใช้เทคนิคการฝึกสมาธิและการส"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =     212.22 ms\n",
            "llama_perf_context_print: prompt eval time =     211.89 ms /    41 tokens (    5.17 ms per token,   193.50 tokens per second)\n",
            "llama_perf_context_print:        eval time =   12351.23 ms /   570 runs   (   21.67 ms per token,    46.15 tokens per second)\n",
            "llama_perf_context_print:       total time =   13539.87 ms /   611 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ังเกต\n",
            "CPU times: user 13.5 s, sys: 116 ms, total: 13.6 s\n",
            "Wall time: 13.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "LsAbegtc43F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stream Response"
      ],
      "metadata": {
        "id": "hNTcEoQx07U1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# llm.generate_kwargs={'temperature': 0.1, 'max_tokens': 1024}\n",
        "# stream_response = llm.stream_complete(\n",
        "#     \"กามโยคะ ภวโยคะ ทิฏฐิโยคะ และอวิชชาโยคะ\"\n",
        "# )\n",
        "# for t in stream_response:\n",
        "#     print(t.delta, end=\"\" , flush=True)\n",
        "# print()"
      ],
      "metadata": {
        "id": "TxO-NNxP027Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# from llama_index.core.llms import ChatMessage\n",
        "\n",
        "# messages = [\n",
        "#     ChatMessage(role=\"system\", content=\"You are an AI assistant that answers questions in Thai language\"),\n",
        "#     ChatMessage(role=\"user\", content=\"กามโยคะ ภวโยคะ ทิฏฐิโยคะ และอวิชชาโยคะ\"),\n",
        "# ]\n",
        "# stream_response = llm.stream_chat(messages)\n",
        "\n",
        "# for t in stream_response:\n",
        "#     print(t.delta, end=\"\" , flush=True)\n",
        "# print()"
      ],
      "metadata": {
        "id": "iIMBgAprIBt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Model"
      ],
      "metadata": {
        "id": "td4o6tXpETUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-m3\")                      # size 8192\n",
        "#embed_model = HuggingFaceEmbedding(model_name=\"intfloat/multilingual-e5-large\")  # size 1024\n",
        "\n",
        "# local file\n",
        "#embed_model = HuggingFaceEmbedding(model_name='/content/drive/MyDrive/EmbeddingModel/bge-m3')"
      ],
      "metadata": {
        "id": "BPCnD1OmmZTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.chunk_size    = 3840\n",
        "Settings.chunk_overlap = 256\n",
        "Settings.llm = llm\n",
        "Settings.embed_model   = embed_model"
      ],
      "metadata": {
        "id": "PMZAXVu4TwMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing"
      ],
      "metadata": {
        "id": "x6coLAhaEiGM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4t_HpOAZ3qL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148,
          "referenced_widgets": [
            "cbc559f9058c457eb8b1daa325319636",
            "812f579aa68a4d008883a5d02f236770",
            "10e0d888b6754e25976219b9bfe9ad82",
            "45ce1610b1fc4c90bca5a2112cf07e07",
            "0bd35319d3ed452d8aa8cd1f6c389343",
            "8d86021fa52540f9b93883bd679dd335",
            "d10282d1e87442588f58e0876a53ce62",
            "7681f9dc7c5f401eb553b6e9528cc5e2",
            "31fb31c0cb6442f482bef234266df26c",
            "ea1106b1b289421f85a8cf6592ce8e1a",
            "5505d5b11dea4b56b5e4980740802947",
            "ec69b3b922ec4c84b8efa67cf377f002",
            "db2dabbdb3f74c6dbc33da2a2755a828",
            "cfbc0c7a6291437fb9619c4faf9e11e6",
            "6bbb2da5605545e884623e5180e2802f",
            "c535e9d97bd342dc80630d982b222da6",
            "1e107b5c4cb64562ba931f68602c18a6",
            "6023ef11b9284d0fa325bf3023854989",
            "a03d48901eb9428297a8af2d66770c1d",
            "1459e943754e467c962c05520d7d57e0",
            "48b0ff3b29c14709a617208af54e34b6",
            "b859b06f01874309a09a9111382e4358",
            "47218e5fece645e392f2024c794b7948",
            "ccd3446ba6c8472c8ef390908878774a",
            "1f15914637004334bafdea1ba972f6ba",
            "6e58d8863b214fac90472944d40501fa",
            "75bb84f218824af594bb1459bd402f6b",
            "0076d54f187b4ccc8d37037e7143f1aa",
            "60fde0d1762e42d9a9af76268f49bfd4",
            "a817d115a7794764ae33dc5bf2f3416c",
            "f695330864b14abcbea95017447bf976",
            "6dff0831f819495093d96fa7c8ab2932",
            "4cf73b368ecf440f90804d82b1cdab63"
          ]
        },
        "outputId": "1c2bc540-ca12-4ad2-bdc4-17a3644f503b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/3039 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbc559f9058c457eb8b1daa325319636"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec69b3b922ec4c84b8efa67cf377f002"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/991 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47218e5fece645e392f2024c794b7948"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4min 27s, sys: 874 ms, total: 4min 28s\n",
            "Wall time: 4min 19s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "index = VectorStoreIndex.from_documents(documents ,show_progress=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywx4UsvIo1SL"
      },
      "source": [
        "## Query\n",
        "Start querying by getting the default query engine\n",
        "https://docs.llamaindex.ai/en/stable/module_guides/querying/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from llama_index.core import PromptTemplate\n",
        "\n",
        "# template = (\n",
        "#     \"Context information is below.\\n\"\n",
        "#     \"---------------------\\n\"\n",
        "#     \"{context_str}\\n\"\n",
        "#     \"---------------------\\n\"\n",
        "#     \"Given the context information and not prior knowledge, \"\n",
        "#     \"answer the query in Thai language.\\n\"\n",
        "#     \"Query: {query_str}\\n\"\n",
        "#     \"Answer: \"\n",
        "# )\n",
        "# prompt_template = PromptTemplate(template)"
      ],
      "metadata": {
        "id": "dGqciUT7RyIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=20,\n",
        "    verbose=True,\n",
        "    streaming=True,\n",
        "    #text_qa_template=prompt_template,\n",
        ")\n",
        "\n",
        "response = query_engine.query(\"วิธีป้องกันฟ้าผ่า\")\n",
        "response.print_response_stream()\n",
        "\n",
        "# display(Markdown(f\"{response}\"))\n",
        "# clear_gpu_memory()"
      ],
      "metadata": {
        "id": "BJXpe50FziVY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19a44245-ded3-477a-83dd-52edd0366a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 9 prefix-match hit, remaining 7071 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4419.93 ms\n",
            "llama_perf_context_print: prompt eval time =    4890.47 ms /  7071 tokens (    0.69 ms per token,  1445.87 tokens per second)\n",
            "llama_perf_context_print:        eval time =   11333.41 ms /   412 runs   (   27.51 ms per token,    36.35 tokens per second)\n",
            "llama_perf_context_print:       total time =   16892.22 ms /  7483 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 6905 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4419.93 ms\n",
            "llama_perf_context_print: prompt eval time =    4770.25 ms /  6905 tokens (    0.69 ms per token,  1447.51 tokens per second)\n",
            "llama_perf_context_print:        eval time =   23645.02 ms /   858 runs   (   27.56 ms per token,    36.29 tokens per second)\n",
            "llama_perf_context_print:       total time =   30195.64 ms /  7763 tokens\n",
            "Llama.generate: 33 prefix-match hit, remaining 2221 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4419.93 ms\n",
            "llama_perf_context_print: prompt eval time =    1107.06 ms /  2221 tokens (    0.50 ms per token,  2006.22 tokens per second)\n",
            "llama_perf_context_print:        eval time =   10978.10 ms /   467 runs   (   23.51 ms per token,    42.54 tokens per second)\n",
            "llama_perf_context_print:       total time =   12874.46 ms /  2688 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 6222 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided context, the refined answer to the query \"วิธีป้องกันฟ้าผ่า\" (How to prevent lightning strikes) is:\n",
            "\n",
            "การป้องกันฟ้าผ่าสามารถทำได้ดังนี้\n",
            "\n",
            "1. ใช้ระบบป้องกันฟ้าผ่า เช่น ระบบป้องกันฟ้าผ่าแบบแอร์เทอร์มินัล (air terminal) หรือ ระบบป้องกันฟ้าผ่าแบบมาสต์ (mast)\n",
            "2. ให้แน่ใจว่าโครงสร้างมีการป้องกันฟ้าผ่าอย่างดี\n",
            "3. พิจารณาประเภทของการก่อสร้าง, ความถี่และความรุนแรงของพายุฟ้าคะนอง, ค่าของอาคารและทรัพย์สิน, ความเสี่ยงต่อผู้คน, ความอ่อนไหวต่อฟ้าผ่า, และเศรษฐศาสตร์เมื่อตัดสินใจว่าจะมีการป้องกันฟ้าผ่าหรือไม่\n",
            "4. ใช้ระบบป้องกันฟ้าผ่าแบบแมทเทอร์ (metallic) หรือ ระบบป้องกันฟ้าผ่าแบบฟาราเดย์ (Faraday) เพื่อป้องกันการเสียหายจากฟ้าผ่า\n",
            "5. ดูแลและทดสอบระบบป้องกันฟ้าผ่าอย่างสม่ำเสมอ\n",
            "\n",
            "นอกจากนี้ยังสามารถใช้ระบบป้องกันฟ้าผ่าแบบอื่นๆ เช่น ระบบป้องกันฟ้าผ่าแบบคาเทนารี (catenary system) หรือ ระบบป้องกันฟ้าผ่าแบบพายเรือ (shipboard lightning protection system) เพื่อป้องกันการเสียหายจากฟ้าผ่า\n",
            "\n",
            "การป้องกันฟ้าผ่าอย่างมีประสิทธิภาพต้องอาศัยการวางแผนและออกแบบระบบป้องกันฟ้าผ่าอย่างดี รวมถึงการดูแลและทดสอบระบบอย่างสม่ำเสมอ เพื่อให้แน่ใจว่าโครงสร้างและทรัพย์สินจะได้รับการป้องกันจากผลกระทบของฟ้าผ่า\n",
            "\n",
            "นอกจากนี้ยังควรพิจารณาถึงความเสี่ยงและความอ่อนไหวต่อฟ้าผ่าของโครงสร้างและทรัพย์สิน รวมถึงความถี่และความรุนแรงของพายุฟ้าคะนอง เพื่อให้สามารถตัดสินใจได้อย่างมีประสิทธิภาพในการป้องกันฟ้าผ่า"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    4419.93 ms\n",
            "llama_perf_context_print: prompt eval time =    4103.33 ms /  6222 tokens (    0.66 ms per token,  1516.33 tokens per second)\n",
            "llama_perf_context_print:        eval time =   14799.77 ms /   548 runs   (   27.01 ms per token,    37.03 tokens per second)\n",
            "llama_perf_context_print:       total time =   20272.95 ms /  6770 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRJ4T8jj4WMU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a136ca20-8970-465a-feff-e6c17304114b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of source nodes: 2\n",
            "Node Score: 0.623294117668057\n",
            "{'page_label': '10', 'file_name': 'พระไตรปิฎก_21อังคุตรนิกาย-จตุกกนิบาต.pdf', 'file_path': '/content/drive/MyDrive/Courses/RAG/C2_Llama3x-RAG-Workshop/dataset/Tri45-5files/พระไตรปิฎก_21อังคุตรนิกาย-จตุกกนิบาต.pdf', 'file_type': 'application/pdf', 'file_size': 1112869, 'creation_date': '2024-12-12', 'last_modified_date': '2024-07-07'}\n",
            "Node Score: 0.5962243557236705\n",
            "{'page_label': '11', 'file_name': 'พระไตรปิฎก_21อังคุตรนิกาย-จตุกกนิบาต.pdf', 'file_path': '/content/drive/MyDrive/Courses/RAG/C2_Llama3x-RAG-Workshop/dataset/Tri45-5files/พระไตรปิฎก_21อังคุตรนิกาย-จตุกกนิบาต.pdf', 'file_type': 'application/pdf', 'file_size': 1112869, 'creation_date': '2024-12-12', 'last_modified_date': '2024-07-07'}\n"
          ]
        }
      ],
      "source": [
        "# Print the number of source nodes\n",
        "num_source_nodes = len(response.source_nodes)\n",
        "print(f\"Number of source nodes: {num_source_nodes}\")\n",
        "\n",
        "# Loop over source nodes and print meta data\n",
        "for s in response.source_nodes:\n",
        "    print(f\"Node Score: {s.score}\")\n",
        "    print(s.node.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.response_txt"
      ],
      "metadata": {
        "id": "cN05L5ks_DY4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "54b712a5-7135-45be-dbd6-6e98a3892ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'กามโยคะ ภวโยคะ ทิฏฐิโยคะ และอวิชชาโยคะ เป็นโยคะ 4 ประการ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "qIfK-Mpu_F_u",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44fd41bc-d40e-40bd-fbfa-dfe49b39dcff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StreamingResponse(response_gen=<generator object stream_completion_response_to_tokens.<locals>.gen at 0x7d3e9f095e50>, source_nodes=[NodeWithScore(node=TextNode(id_='9157334f-e405-4cf5-ae51-dad504191b28', embedding=None, metadata={'page_label': '10', 'file_name': 'พระไตรปิฎก_21อังคุตรนิกาย-จตุกกนิบาต.pdf', 'file_path': '/content/drive/MyDrive/Courses/RAG/C2_Llama3x-RAG-Workshop/dataset/Tri45-5files/พระไตรปิฎก_21อังคุตรนิกาย-จตุกกนิบาต.pdf', 'file_type': 'application/pdf', 'file_size': 1112869, 'creation_date': '2024-12-12', 'last_modified_date': '2024-07-07'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='fbbab046-4bb1-4348-a189-fab23435ef1a', node_type='4', metadata={'page_label': '10', 'file_name': 'พระไตรปิฎก_21อังคุตรนิกาย-จตุกกนิบาต.pdf', 'file_path': '/content/drive/MyDrive/Courses/RAG/C2_Llama3x-RAG-Workshop/dataset/Tri45-5files/พระไตรปิฎก_21อังคุตรนิกาย-จตุกกนิบาต.pdf', 'file_type': 'application/pdf', 'file_size': 1112869, 'creation_date': '2024-12-12', 'last_modified_date': '2024-07-07'}, hash='9ed1b89a0c41ef3baf6334f6da991047c2f447d55a91327ac1e60406b000ac42')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='พระสุตตันตป\\uf701ฎก เล\\uf70aม ๑๓ อังคุตรนิกาย จตุกกนิบาต - หน\\uf70bาที่ 10 \\n โทษ และอุบายเครื่องสลัดออกแห\\uf70aงทิฐิทั้งหลาย ตามความเป\\uf712นจริง ความกําหนัดเพราะทิฐิ  \\nความเพลิดเพลินเพราะทิฐิความเยื่อใยเพราะทิฐิ ความหมกมุ\\uf70aนเพราะทิฐิ ความกระหายเพราะ \\nทิฐิ ความเร\\uf70aาร\\uf70bอนเพราะทิฐิ ความหยั่งลงเพราะทิฐิ และความทะยานอยากเพราะทิฐิ ในทิฐิ \\nทั้งหลาย ย\\uf70aอมเกิดขึ้น นี้เราเรียกว\\uf70aาทิฏฐิโยคะ กามโยคะ ภวโยคะ ทิฏฐิโย คะเป \\uf712นดังนี้ ก็อวิชชา \\nโยคะเป\\uf712นไฉน บุคคลบางคนในโลกนี้ ย\\uf70aอมไม\\uf70aรู\\uf70bชัดซึ่งความเกิด ความดับ คุณ โทษ และอุบาย \\nเครื่องสลัดออกแห\\uf70aงผัสสายตนะ ๖ ประการตามความเป\\uf712นจริง เมื่อเขาไม\\uf70aรู\\uf70bชัดซึ่งความเกิด ความดับ  \\nคุณ โทษ และอุบายเครื่องสลัดออกแห\\uf70aงผัสสายตนะ ๖ ประการ ตามความเป\\uf712นจริง ความไม\\uf70aรู\\uf70b  \\nความไม\\uf70aหยั่งรู\\uf70b ในผัสสายตนะ ๖ ย\\uf70aอมเกิดขึ้น นี้เราเรียกว\\uf70aาอวิชชาโยคะ กามโยคะ ภวโ ยคะ  \\nทิฏฐิโยคะ และอวิชชาโยคะ เป\\uf712นดังนี้ บุคคลผู\\uf70bประกอบด\\uf70bวยอกุศลธรรมอันลามก อันเป\\uf712นเครื่อง \\nเศร\\uf70bาหมอง เป\\uf712นเหตุให\\uf70bเกิดในภพใหม\\uf70a มีความกระวนกระวาย มีทุกข\\uf70eเป\\uf712นวิบาก มีชาติ ชราและ \\nมรณะต\\uf70aอไปอีก ฉะนั้น เราจึงเรียกว\\uf70aา ผู\\uf70bไม\\uf70aเกษมจากโยคะ ดูกรภิกษุทั้งหลาย โยคะ ๔ ประการ \\nเหล\\uf70aานี้แล ฯ \\n      ดูกรภิกษุทั้งหลาย ความพรากจากโยคะ ๔ ประการนี้ ๔ ประการเป\\uf712นไฉน คือ ความ \\nพรากจากกามโยคะ ๑ ความพรากจากภวโยคะ ๑ ความพรากจากทิฏฐิโย\\nคะ ๑ ความพรากจากอวิชชา \\nโยคะ ๑ ดูกรภิกษุทั้งหลาย ก็ความพรากจากกามโยคะเป\\uf712นไฉน บุคคลบางคนในโลกนี้ ย\\uf70aอมรู\\uf70bชัดซึ่ง \\nความเกิดความดับ คุณ โทษ และอุบายเครื่องสลัดออกแห\\uf70aงกามทั้งหลาย ตามความเป\\uf712นจริง เมื่อเขา \\nรู\\uf70bชัดซึ่งความเกิด ความดับ คุณ โทษ แล ะอ ุบายเครื่องสลัดออกแห\\uf70aงกามทั้งหลาย ตามความเป\\uf712นจริง \\n ความกําหนัดเพราะกาม ความเพลิดเพลินเพราะกาม ความเยื่อใยเพราะกาม ความหมกมุ\\uf70aนเพราะกาม  \\nความกระหายเพราะกาม ความเร\\uf70aาร\\uf70bอนเพราะกาม ความหยั่งลงในกาม ความทะยานอยากเพราะกาม \\n ในกามทั้งหลาย ย\\uf70aอมไม\\uf70aเกิดขึ้น นี้เราเรียกว\\uf70aาความพรากจากกามโยคะความพรากจากกามโยคะเป\\uf712น \\nดังนี้ ก็ความพรากจากภวโยคะเป\\uf712นไฉน ดูกรภิกษุทั้งหลาย บุคคลบางคนในโลกนี้ ย\\uf70aอมรู\\uf70bชัดซึ่ง \\nความเกิด ความดับ คุณ โทษและอุบายเครื่องสลัดออกแห\\uf70aงภพทั้งห ลาย  ตามความเป\\uf712นจริง  \\nเมื่อเขารู\\uf70bชัดซึ่งความเกิด ความดับ คุณ โทษ และอุบายเครื่องสลัดออกแห\\uf70aงภพทั้งหลายตามความ \\nเป\\uf712นจริง ความกําหนัดเพราะภพ ความเพลิดเพลินเพราะภพ ความเยื่อใยเพราะภพ ความหมกมุ\\uf70aน \\nเพราะภพ ความกระหายเพราะภพ ความเร\\uf70aาร\\uf70bอนเพราะภพ ความหยั่งลงในภพ และความทะยาน \\nอยากเพราะภพ ในภพทั้งหลายย\\uf70aอมไม\\uf70aเกิดขึ้น นี้เราเรียกว\\uf70aาความพรากจากภวโยคะ ความพรากจาก \\nกามโยคะความพรากจากภวโยคะ เป\\uf712นดังนี้ ก็ความพรากจากทิฏฐิโยคะเป\\uf712นไฉน ดูกรภิกษุ', mimetype='text/plain', start_char_idx=0, end_char_idx=2267, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.623294117668057), NodeWithScore(node=TextNode(id_='04447e70-06cc-442e-9754-ac54014d783f', embedding=None, metadata={'page_label': '11', 'file_name': 'พระไตรปิฎก_21อังคุตรนิกาย-จตุกกนิบาต.pdf', 'file_path': '/content/drive/MyDrive/Courses/RAG/C2_Llama3x-RAG-Workshop/dataset/Tri45-5files/พระไตรปิฎก_21อังคุตรนิกาย-จตุกกนิบาต.pdf', 'file_type': 'application/pdf', 'file_size': 1112869, 'creation_date': '2024-12-12', 'last_modified_date': '2024-07-07'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='fdd12a8b-1414-4f97-a03a-f2f1c3640041', node_type='4', metadata={'page_label': '11', 'file_name': 'พระไตรปิฎก_21อังคุตรนิกาย-จตุกกนิบาต.pdf', 'file_path': '/content/drive/MyDrive/Courses/RAG/C2_Llama3x-RAG-Workshop/dataset/Tri45-5files/พระไตรปิฎก_21อังคุตรนิกาย-จตุกกนิบาต.pdf', 'file_type': 'application/pdf', 'file_size': 1112869, 'creation_date': '2024-12-12', 'last_modified_date': '2024-07-07'}, hash='e218c15620c67718951366fea01abef8539031b1e85c538fc395c4e0c8e9fc8f')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='พระสุตตันตป\\uf701ฎก เล\\uf70aม ๑๓ อังคุตรนิกาย จตุกกนิบาต - หน\\uf70bาที่ 11 \\nทั้งหลาย บุคคลบางคนในโลกนี้ ย\\uf70aอมรู\\uf70bชัดซึ่งความเกิด ความดับ คุณ โทษและอุบายเครื่องสลัด \\nออกแห\\uf70aงทิฐิทั้งหลาย ตามความเป\\uf712นจริง เมื่อเขารู\\uf70bชัดซึ่งความเกิด ความดับ คุณ โทษ และ \\nอุบายเครื่องสลัดออกแห\\uf70aงทิฐิทั้งหลายตามความเป\\uf712นจริง ความกําหนัดเพราะทิฐิ ความเพลิดเพลิน \\nเพราะทิฐิ คว ามเย ื่อใยเพราะทิฐิ ความหมกมุ\\uf70aนเพราะทิฐิ ความกระหายเพราะทิฐิ ความ \\nเร\\uf70aาร\\uf70bอนเพราะทิฐิ ความหยั่งลงในทิฐิ และความทะยานอยากเพราะทิฐิ ในทิฐิทั้งหลายย\\uf70aอม \\nไม\\uf70aเกิดขึ้น นี้เราเรียกว\\uf70aาความพรากจากทิฏฐิโยคะ ความพรากจากกามโยคะความพรากจากภวโยคะ  \\nความพรากจากทิฏฐิโยคะ เป\\uf712นดังนี้ ก็ความพรากจากอวิชชาโยคะเป\\uf712นไฉน ดูกรภิกษุทั้งหลาย  \\nบุคคลบางคนในโลกนี้ ย\\uf70aอมรู\\uf70bชัดซึ่ง ความเกิด ความดับ คุณ โทษ และอุบายเครื่องสลัดออกแห\\uf70aง \\nผัสสายตนะ ๖ประการ ตามความเป\\uf712นจริง เมื่อเขารู\\uf70bชัดซึ่งความเกิด คว ามดับ คุณ โทษและ \\nอุบายเครื่องสลัดออกแห\\uf70aงผัสสายตนะ ๖ ประการ ตามความเป\\uf712นจริง ความไม\\uf70aรู\\uf70b ความไม\\uf70aหยั่งรู\\uf70b  \\nในผัสสายตนะ ๖ ประการ ย\\uf70aอมไม\\uf70aเกิดขึ้น นี้เราเรียกว\\uf70aาความพรากจากอวิชชาโยคะ ความพรากจาก \\nกามโยคะ ความพรากจากภวโยคะความพรากจากทิฏฐิโยคะ เป\\uf712นดังนี้ บุคคลผู\\uf70bพรากจากอกุศล \\nธรรมอันลามก อันเป\\uf712นเครื่องเศร\\uf70bาหมอง เป\\uf712นเหตุให\\uf70bเกิดในภพใหม\\uf70a มีความกระวนกระวาย มีทุกข\\uf70e \\nเป\\uf712นวิบาก มีชาติ ชรา และมรณะต\\uf70aอไปอีก ฉะนั้น เราจึงเรียกว\\uf70aา ผู\\uf70bเกษม\\nจากโยคะ ดูกรภิกษุ \\nทั้งหลาย ความพรากจากโยคะ ๔ ประการ นี้แล ฯ \\n      สัตว\\uf70eทั้งหลายผู\\uf70bประกอบด\\uf70bวยกามโยคะ ภวโยคะ ทิฏฐิโยคะ \\n      และอวิชชาโยคะ ย\\uf70aอมเป\\uf712นผู\\uf70bมีปรกติถึงชาติและมรณะ \\n     ไปสู\\uf70a  สงสาร ส\\uf70aวนสัตว\\uf70eเหล\\uf70aาใด กําหนดรู\\uf70bกามทั้งหลายและ \\n      ภวโยคะโดยประการทั้งปวง ถอนขึ้นซึ่งทิฏฐิโยคะ \\n     และสํารอก    อวิชชาเสียได\\uf70b สัตว\\uf70eเหล\\uf70aานั้นแล เป\\uf712นผู\\uf70b \\n     พรากจากโ\\nยคะทั้งปวง เป\\uf712นมุนีผู\\uf70bล\\uf70aวงพ\\uf70bนโยคะเสียได\\uf70b ฯ \\n                                                    จบสูตรที่ ๑๐ \\n                                                 จบภัณฑคามวรรคที่ ๑ \\n                                           ___________________ \\n                                  รวมพระสูตรที่มีในวรรคนี้ คือ \\n     ๑. อนุพุทธสูตร ๒. ปปติตสูตร ๓. ขตสูตรที่ ๑ ๔. ขตสูตรที่ ๒  ๕. อนุโสตสูตร  \\n๖. อัปปสุตสูตร ๗. สังฆโสภณสูตร ๘. เวส ารัชชสูตร๙. ตัณหาสูตร ๑๐. โยคสูตร \\n                                     ________________', mimetype='text/plain', start_char_idx=0, end_char_idx=2095, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.5962243557236705)], metadata={'9157334f-e405-4cf5-ae51-dad504191b28': {'page_label': '10', 'file_name': 'พระไตรปิฎก_21อังคุตรนิกาย-จตุกกนิบาต.pdf', 'file_path': '/content/drive/MyDrive/Courses/RAG/C2_Llama3x-RAG-Workshop/dataset/Tri45-5files/พระไตรปิฎก_21อังคุตรนิกาย-จตุกกนิบาต.pdf', 'file_type': 'application/pdf', 'file_size': 1112869, 'creation_date': '2024-12-12', 'last_modified_date': '2024-07-07'}, '04447e70-06cc-442e-9754-ac54014d783f': {'page_label': '11', 'file_name': 'พระไตรปิฎก_21อังคุตรนิกาย-จตุกกนิบาต.pdf', 'file_path': '/content/drive/MyDrive/Courses/RAG/C2_Llama3x-RAG-Workshop/dataset/Tri45-5files/พระไตรปิฎก_21อังคุตรนิกาย-จตุกกนิบาต.pdf', 'file_type': 'application/pdf', 'file_size': 1112869, 'creation_date': '2024-12-12', 'last_modified_date': '2024-07-07'}}, response_txt='กามโยคะ ภวโยคะ ทิฏฐิโยคะ และอวิชชาโยคะ เป็นโยคะ 4 ประการ')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNVgRgycmlYv"
      },
      "source": [
        "## Storing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bjDrdRag_3Q"
      },
      "outputs": [],
      "source": [
        "index.storage_context.persist(persist_dir=\"./storage\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp -r ./storage /content/drive/MyDrive/Courses/RAG/storage"
      ],
      "metadata": {
        "id": "-tfyMR-gCwC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Index"
      ],
      "metadata": {
        "id": "lt1RwgVU7Z2V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjcYRoSlhAAS"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "\n",
        "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
        "#storage_context = StorageContext.from_defaults(persist_dir=\"/content/drive/MyDrive/TrainModel/storage_tri45\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emO65gB34ZwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb3241f-3a88-4bd7-fb78-8d7bea3e4169"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaCPP(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7ad8c655e990>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x7ad8c5f3c900>, completion_to_prompt=<function completion_to_prompt at 0x7ad8c5f3c860>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, model_url='https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf', model_path='/tmp/llama_index/models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf', temperature=0.1, max_new_tokens=1024, context_window=8192, generate_kwargs={'temperature': 0.1, 'max_tokens': 1024}, model_kwargs={'n_ctx': 8192, 'verbose': True, 'repetition-penalty': 1.4, 'no_repeat_ngram_size': 4, 'n_gpu_layers': -1}, verbose=True)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "llm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model"
      ],
      "metadata": {
        "id": "GjbsXzuf7tH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf63167-bacd-40b1-e7b0-913626621c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HuggingFaceEmbedding(model_name='BAAI/bge-m3', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7ad654597510>, num_workers=None, max_length=8192, normalize=True, query_instruction=None, text_instruction=None, cache_folder=None, show_progress_bar=False)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "# Settings.chunk_size    = 3840\n",
        "# Settings.chunk_overlap = 256\n",
        "Settings.llm         = llm\n",
        "Settings.embed_model = embed_model"
      ],
      "metadata": {
        "id": "f_6dV79-ZIme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_index = load_index_from_storage(storage_context=storage_context)\n",
        "load_index"
      ],
      "metadata": {
        "id": "EhMWTAgoljrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f642bc03-5a91-4b1b-b7c0-4cf115ad56ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x7ad64a2f3890>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Query as Retriever in Vector Database only**\n",
        "\n",
        "Node Postprocessor   \n",
        "https://docs.llamaindex.ai/en/stable/module_guides/querying/node_postprocessors/"
      ],
      "metadata": {
        "id": "jqTs5-OK9L87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retrieval_engine = load_index.as_retriever(similarity_top_k=2)\n",
        "response         = retrieval_engine.retrieve(\"กามโยคะ ภวโยคะ ทิฏฐิโยคะ และอวิชชาโยคะ\")\n",
        "display(Markdown(f\"{response[0]}\"))\n",
        "display(Markdown(f\"{response[1]}\"))"
      ],
      "metadata": {
        "id": "CACp9UHW8xEq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "7bce19ec-e65a-4701-a7ea-312476b55027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Node ID: 9157334f-e405-4cf5-ae51-dad504191b28\nText: พระสุตตันตปฎก เลม ๑๓ อังคุตรนิกาย จตุกกนิบาต - หนาที่ 10\nโทษ และอุบายเครื่องสลัดออกแหงทิฐิทั้งหลาย ตามความเปนจริง\nความกําหนัดเพราะทิฐิ   ความเพลิดเพลินเพราะทิฐิความเยื่อใยเพราะทิฐิ\nความหมกมุนเพราะทิฐิ ความกระหายเพราะ  ทิฐิ ความเรารอนเพราะทิฐิ\nความหยั่งลงเพราะทิฐิ และความทะยานอยากเพราะทิฐิ ในทิฐิ  ทั้งหลาย\nยอมเกิดขึ้น นี้เราเรียกวาทิฏ...\nScore:  0.623\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Node ID: 04447e70-06cc-442e-9754-ac54014d783f\nText: พระสุตตันตปฎก เลม ๑๓ อังคุตรนิกาย จตุกกนิบาต - หนาที่ 11\nทั้งหลาย บุคคลบางคนในโลกนี้ ยอมรูชัดซึ่งความเกิด ความดับ คุณ\nโทษและอุบายเครื่องสลัด  ออกแหงทิฐิทั้งหลาย ตามความเปนจริง\nเมื่อเขารูชัดซึ่งความเกิด ความดับ คุณ โทษ และ\nอุบายเครื่องสลัดออกแหงทิฐิทั้งหลายตามความเปนจริง\nความกําหนัดเพราะทิฐิ ความเพลิดเพลิน  เพราะทิฐิ คว ามเย ื่อใยเพรา...\nScore:  0.596\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Query with LLM\n",
        "Response Mode\n",
        "https://docs.llamaindex.ai/en/stable/module_guides/deploying/query_engine/response_modes/"
      ],
      "metadata": {
        "id": "IWUQw6aL_djU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "-fwNmti1euXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "llm.generate_kwargs={'temperature': 0.1, 'max_tokens': 512}\n",
        "\n",
        "query_engine = load_index.as_query_engine(\n",
        "    similarity_top_k=4 ,\n",
        "    streaming=True)\n",
        "response     = query_engine.query(\"กามโยคะ ภวโยคะ ทิฏฐิโยคะ และอวิชชาโยคะ\")\n",
        "response.print_response_stream()\n",
        "#display(Markdown(f\"{response}\"))"
      ],
      "metadata": {
        "id": "1huqPzIX9pRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab3bb7c6-11ac-44ee-f1c8-04f41d4be835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    2039.96 ms\n",
            "llama_perf_context_print: prompt eval time =    2039.23 ms /  3667 tokens (    0.56 ms per token,  1798.23 tokens per second)\n",
            "llama_perf_context_print:        eval time =     859.58 ms /    35 runs   (   24.56 ms per token,    40.72 tokens per second)\n",
            "llama_perf_context_print:       total time =    2945.59 ms /  3702 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 1302 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "กามโยคะ ภวโยคะ ทิฏฐิโยคะ และอวิชชาโยคะ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    2039.96 ms\n",
            "llama_perf_context_print: prompt eval time =     589.02 ms /  1302 tokens (    0.45 ms per token,  2210.45 tokens per second)\n",
            "llama_perf_context_print:        eval time =     593.28 ms /    26 runs   (   22.82 ms per token,    43.82 tokens per second)\n",
            "llama_perf_context_print:       total time =    1231.54 ms /  1328 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.11 s, sys: 283 ms, total: 4.39 s\n",
            "Wall time: 4.36 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat Engine\n",
        "\n",
        "usage pattern guide.   \n",
        "https://docs.llamaindex.ai/en/stable/module_guides/deploying/chat_engines/usage_pattern/"
      ],
      "metadata": {
        "id": "iDcoUedn9rD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_engine = load_index.as_chat_engine(\n",
        "    llm=llm,\n",
        "    similarity_top_k=1,\n",
        "    chat_mode=\"condense_question\",\n",
        "    streaming=True,\n",
        "    verbose=True,\n",
        ")\n",
        "#chat_engine.reset()"
      ],
      "metadata": {
        "id": "6sxGxBIhRIcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collected_messages = []\n",
        "\n",
        "streaming_response = chat_engine.stream_chat(\"กามโยคะ ภวโยคะ ทิฏฐิโยคะ และอวิชชาโยคะ\")\n",
        "for token in streaming_response.response_gen:\n",
        "    print(token, end=\"\")\n",
        "    collected_messages.append(token)\n",
        "\n",
        "full_message = ''.join(collected_messages)\n",
        "display(Markdown(f\"{full_message}\"))"
      ],
      "metadata": {
        "id": "h1Cwlo3WR7qp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "f5aad089-2b93-4206-9c11-e703e88189de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Querying with: กามโยคะ ภวโยคะ ทิฏฐิโยคะ และอวิชชาโยคะ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 9 prefix-match hit, remaining 1376 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "กามโยคะ ภวโยคะ ทิฏฐิโยคะ และอวิชชาโยคะ เป"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    2039.96 ms\n",
            "llama_perf_context_print: prompt eval time =     613.05 ms /  1376 tokens (    0.45 ms per token,  2244.51 tokens per second)\n",
            "llama_perf_context_print:        eval time =     797.93 ms /    35 runs   (   22.80 ms per token,    43.86 tokens per second)\n",
            "llama_perf_context_print:       total time =    1462.63 ms /  1411 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "็นโยคะ 4 ประการ"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "กามโยคะ ภวโยคะ ทิฏฐิโยคะ และอวิชชาโยคะ เป็นโยคะ 4 ประการ"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rerank"
      ],
      "metadata": {
        "id": "SFfccRubVoQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.postprocessor.flag_embedding_reranker import (\n",
        "    FlagEmbeddingReranker,\n",
        ")\n",
        "rerank = FlagEmbeddingReranker(model=\"BAAI/bge-reranker-v2-m3\", top_n=5)"
      ],
      "metadata": {
        "id": "8y7Ljq_tV7p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "SfeeM9vxe9wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "query_engine = load_index.as_query_engine(\n",
        "    similarity_top_k=10,\n",
        "    streaming=True,\n",
        "    node_postprocessors=[rerank]\n",
        ")\n",
        "\n",
        "response = query_engine.query(\n",
        "    \"กามโยคะ ภวโยคะ ทิฏฐิโยคะ และอวิชชาโยคะ\",\n",
        ")\n",
        "response.print_response_stream()"
      ],
      "metadata": {
        "id": "84jAOoIYXAEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG Summarization Tool"
      ],
      "metadata": {
        "id": "i2TqqaOKNfvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "g5MCqRhkgquS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "# load documents\n",
        "#documents = SimpleDirectoryReader(input_files=[\"metagpt.pdf\"]).load_data()\n",
        "documents = SimpleDirectoryReader(\n",
        "    input_files=[\"/content/drive/MyDrive/Dataset/Tri45-5files/พระไตรปิฎก_21อังคุตรนิกาย-จตุกกนิบาต.pdf\"]).load_data()\n",
        "len(documents)"
      ],
      "metadata": {
        "id": "MYncLX1-RhxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = documents[:10]"
      ],
      "metadata": {
        "id": "H3Iu21nYlp-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "splitter = SentenceSplitter(chunk_size=3840 ,chunk_overlap=256)\n",
        "nodes    = splitter.get_nodes_from_documents(documents ,show_progress=True)"
      ],
      "metadata": {
        "id": "Jyz2A37pRe62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SummaryIndex\n",
        "\n",
        "summary_index  = SummaryIndex(nodes)\n",
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\",\n",
        "    use_async=True,\n",
        "    verbose=False,\n",
        "    streaming=True,\n",
        ")"
      ],
      "metadata": {
        "id": "47PzdGRXbSsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "llm.generate_kwargs={'temperature': 0.8, 'max_tokens': 2048}\n",
        "\n",
        "response = summary_query_engine.query(\n",
        "    \"สรุปเอกสาร เป็นแต่ละหัวข้อ พร้อมอธิบายเนื้อหาและยกตัวอย่างประกอบ\"\n",
        ")\n",
        "response.print_response_stream()"
      ],
      "metadata": {
        "id": "95UqCAXxNkub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_source_nodes = len(response.source_nodes)\n",
        "print(f\"Number of source nodes: {num_source_nodes}\")\n",
        "\n",
        "# Loop over source nodes and print meta data\n",
        "for s in response.source_nodes:\n",
        "    print(f\"Node Score: {s.score}\")\n",
        "    print(s.node.metadata)"
      ],
      "metadata": {
        "id": "7k0MlskMNmAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced RAG (Routing, Sub-Questions)"
      ],
      "metadata": {
        "id": "nW5R89hCNpt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "\n",
        "# vector_tool = QueryEngineTool(\n",
        "#     index.as_query_engine(),\n",
        "#     metadata=ToolMetadata(\n",
        "#         name=\"vector_search\",\n",
        "#         description=\"Useful for searching for specific facts.\",\n",
        "#     ),\n",
        "# )\n",
        "\n",
        "# summary_tool = QueryEngineTool(\n",
        "#     index.as_query_engine(response_mode=\"tree_summarize\"),\n",
        "#     metadata=ToolMetadata(\n",
        "#         name=\"summary\",\n",
        "#         description=\"Useful for summarizing an entire document.\",\n",
        "#     ),\n",
        "# )"
      ],
      "metadata": {
        "id": "C_nL6E8rNovE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from llama_index.core.query_engine import RouterQueryEngine\n",
        "\n",
        "# query_engine = RouterQueryEngine.from_defaults(\n",
        "#     [vector_tool, summary_tool],\n",
        "#     select_multi=False,\n",
        "#     verbose=True\n",
        "# )\n",
        "\n",
        "# response = query_engine.query(\n",
        "#     \"Tell me about the song meet the grahams - why is it significant\"\n",
        "# )\n",
        "\n",
        "# display(Markdown(f\"{response}\"))\n",
        "# print(len(str(response)))"
      ],
      "metadata": {
        "id": "tYys-BjgNtwc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "hNTcEoQx07U1",
        "SFfccRubVoQN",
        "i2TqqaOKNfvk",
        "nW5R89hCNpt7"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cbc559f9058c457eb8b1daa325319636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_812f579aa68a4d008883a5d02f236770",
              "IPY_MODEL_10e0d888b6754e25976219b9bfe9ad82",
              "IPY_MODEL_45ce1610b1fc4c90bca5a2112cf07e07"
            ],
            "layout": "IPY_MODEL_0bd35319d3ed452d8aa8cd1f6c389343"
          }
        },
        "812f579aa68a4d008883a5d02f236770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d86021fa52540f9b93883bd679dd335",
            "placeholder": "​",
            "style": "IPY_MODEL_d10282d1e87442588f58e0876a53ce62",
            "value": "Parsing nodes: 100%"
          }
        },
        "10e0d888b6754e25976219b9bfe9ad82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7681f9dc7c5f401eb553b6e9528cc5e2",
            "max": 3039,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31fb31c0cb6442f482bef234266df26c",
            "value": 3039
          }
        },
        "45ce1610b1fc4c90bca5a2112cf07e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea1106b1b289421f85a8cf6592ce8e1a",
            "placeholder": "​",
            "style": "IPY_MODEL_5505d5b11dea4b56b5e4980740802947",
            "value": " 3039/3039 [00:01&lt;00:00, 1535.01it/s]"
          }
        },
        "0bd35319d3ed452d8aa8cd1f6c389343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d86021fa52540f9b93883bd679dd335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d10282d1e87442588f58e0876a53ce62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7681f9dc7c5f401eb553b6e9528cc5e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31fb31c0cb6442f482bef234266df26c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea1106b1b289421f85a8cf6592ce8e1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5505d5b11dea4b56b5e4980740802947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec69b3b922ec4c84b8efa67cf377f002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db2dabbdb3f74c6dbc33da2a2755a828",
              "IPY_MODEL_cfbc0c7a6291437fb9619c4faf9e11e6",
              "IPY_MODEL_6bbb2da5605545e884623e5180e2802f"
            ],
            "layout": "IPY_MODEL_c535e9d97bd342dc80630d982b222da6"
          }
        },
        "db2dabbdb3f74c6dbc33da2a2755a828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e107b5c4cb64562ba931f68602c18a6",
            "placeholder": "​",
            "style": "IPY_MODEL_6023ef11b9284d0fa325bf3023854989",
            "value": "Generating embeddings: 100%"
          }
        },
        "cfbc0c7a6291437fb9619c4faf9e11e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a03d48901eb9428297a8af2d66770c1d",
            "max": 2048,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1459e943754e467c962c05520d7d57e0",
            "value": 2048
          }
        },
        "6bbb2da5605545e884623e5180e2802f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48b0ff3b29c14709a617208af54e34b6",
            "placeholder": "​",
            "style": "IPY_MODEL_b859b06f01874309a09a9111382e4358",
            "value": " 2048/2048 [02:55&lt;00:00, 10.19it/s]"
          }
        },
        "c535e9d97bd342dc80630d982b222da6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e107b5c4cb64562ba931f68602c18a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6023ef11b9284d0fa325bf3023854989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a03d48901eb9428297a8af2d66770c1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1459e943754e467c962c05520d7d57e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48b0ff3b29c14709a617208af54e34b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b859b06f01874309a09a9111382e4358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47218e5fece645e392f2024c794b7948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccd3446ba6c8472c8ef390908878774a",
              "IPY_MODEL_1f15914637004334bafdea1ba972f6ba",
              "IPY_MODEL_6e58d8863b214fac90472944d40501fa"
            ],
            "layout": "IPY_MODEL_75bb84f218824af594bb1459bd402f6b"
          }
        },
        "ccd3446ba6c8472c8ef390908878774a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0076d54f187b4ccc8d37037e7143f1aa",
            "placeholder": "​",
            "style": "IPY_MODEL_60fde0d1762e42d9a9af76268f49bfd4",
            "value": "Generating embeddings: 100%"
          }
        },
        "1f15914637004334bafdea1ba972f6ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a817d115a7794764ae33dc5bf2f3416c",
            "max": 991,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f695330864b14abcbea95017447bf976",
            "value": 991
          }
        },
        "6e58d8863b214fac90472944d40501fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dff0831f819495093d96fa7c8ab2932",
            "placeholder": "​",
            "style": "IPY_MODEL_4cf73b368ecf440f90804d82b1cdab63",
            "value": " 991/991 [01:21&lt;00:00, 28.17it/s]"
          }
        },
        "75bb84f218824af594bb1459bd402f6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0076d54f187b4ccc8d37037e7143f1aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60fde0d1762e42d9a9af76268f49bfd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a817d115a7794764ae33dc5bf2f3416c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f695330864b14abcbea95017447bf976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6dff0831f819495093d96fa7c8ab2932": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cf73b368ecf440f90804d82b1cdab63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}