{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/klinsc/sdd-nonggof-v1/blob/main/2_Llama3_x_GGUF_RAG_LlamaIndex_pdf_colab_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlVz3NHxgk0h"
      },
      "source": [
        "<p>\n",
        "    <img src=\"https://cdn-uploads.huggingface.co/production/uploads/6424f01ea4f3051f54dbbd85/oqVQ04b5KiGt5WOWJmYt8.png\" alt=\"LlamaIndex\" width=\"100\" height=\"100\">\n",
        "    <img src=\"https://cdn4.iconfinder.com/data/icons/file-extensions-1/64/pdfs-512.png\" alt=\"PDF\" width=\"100\" height=\"100\">\n",
        "    <img src=\"https://huggingface.co/front/assets/huggingface_logo-noborder.svg\" alt=\"PDF\" width=\"100\" height=\"100\">\n",
        "</p>\n",
        "\n",
        "# LlamaIndex\n",
        "## [Youtube Video covering this notebook](https://youtu.be/QNKeNiRjtGQ?si=UFH9WL5nXvmj2EM1)\n",
        "- [LlamaIndex Website](https://www.llamaindex.ai/)\n",
        "- [LangChain Website](https://python.langchain.com/docs/get_started/introduction)\n",
        "-[Retrieval-Augmented Generation (RAG)](https://research.ibm.com/blog/retrieval-augmented-generation-RAG)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YMfROowrS-kG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "520f51cb-4978-4cd4-c56d-b3043b07943c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoDC_DKkj6Ga"
      },
      "source": [
        "## Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nW_0yKusLRWK"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install llama-index\n",
        "!pip install llama-index-llms-llama-cpp\n",
        "!pip install llama-index-embeddings-huggingface\n",
        "\n",
        "!pip install llama-index-postprocessor-flag-embedding-reranker\n",
        "!pip install git+https://github.com/FlagOpen/FlagEmbedding.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4HkW33bQE2VI",
        "outputId": "22b600e7-712b-49d5-fb3c-429a14cbfc51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                                           Version\n",
            "------------------------------------------------- -------------------\n",
            "absl-py                                           1.4.0\n",
            "accelerate                                        1.7.0\n",
            "aiohappyeyeballs                                  2.6.1\n",
            "aiohttp                                           3.11.15\n",
            "aiosignal                                         1.3.2\n",
            "aiosqlite                                         0.21.0\n",
            "alabaster                                         1.0.0\n",
            "albucore                                          0.0.24\n",
            "albumentations                                    2.0.7\n",
            "ale-py                                            0.11.0\n",
            "altair                                            5.5.0\n",
            "annotated-types                                   0.7.0\n",
            "antlr4-python3-runtime                            4.9.3\n",
            "anyio                                             4.9.0\n",
            "argon2-cffi                                       23.1.0\n",
            "argon2-cffi-bindings                              21.2.0\n",
            "array_record                                      0.7.2\n",
            "arviz                                             0.21.0\n",
            "astropy                                           7.1.0\n",
            "astropy-iers-data                                 0.2025.5.19.0.38.36\n",
            "astunparse                                        1.6.3\n",
            "atpublic                                          5.1\n",
            "attrs                                             25.3.0\n",
            "audioread                                         3.0.1\n",
            "autograd                                          1.8.0\n",
            "babel                                             2.17.0\n",
            "backcall                                          0.2.0\n",
            "backports.tarfile                                 1.2.0\n",
            "banks                                             2.1.2\n",
            "beautifulsoup4                                    4.13.4\n",
            "betterproto                                       2.0.0b6\n",
            "bigframes                                         2.4.0\n",
            "bigquery-magics                                   0.9.0\n",
            "bleach                                            6.2.0\n",
            "blinker                                           1.9.0\n",
            "blis                                              1.3.0\n",
            "blobfile                                          3.0.0\n",
            "blosc2                                            3.3.3\n",
            "bokeh                                             3.7.3\n",
            "Bottleneck                                        1.4.2\n",
            "bqplot                                            0.12.45\n",
            "branca                                            0.8.1\n",
            "build                                             1.2.2.post1\n",
            "CacheControl                                      0.14.3\n",
            "cachetools                                        5.5.2\n",
            "catalogue                                         2.0.10\n",
            "cbor                                              1.0.0\n",
            "certifi                                           2025.4.26\n",
            "cffi                                              1.17.1\n",
            "chardet                                           5.2.0\n",
            "charset-normalizer                                3.4.2\n",
            "chex                                              0.1.89\n",
            "clarabel                                          0.10.0\n",
            "click                                             8.2.1\n",
            "cloudpathlib                                      0.21.1\n",
            "cloudpickle                                       3.1.1\n",
            "cmake                                             3.31.6\n",
            "cmdstanpy                                         1.2.5\n",
            "colorama                                          0.4.6\n",
            "colorcet                                          3.1.0\n",
            "colorlover                                        0.3.0\n",
            "colour                                            0.1.5\n",
            "community                                         1.0.0b1\n",
            "confection                                        0.1.5\n",
            "cons                                              0.4.6\n",
            "contourpy                                         1.3.2\n",
            "cramjam                                           2.10.0\n",
            "cryptography                                      43.0.3\n",
            "cuda-python                                       12.6.2.post1\n",
            "cudf-cu12                                         25.2.1\n",
            "cudf-polars-cu12                                  25.2.2\n",
            "cufflinks                                         0.17.3\n",
            "cuml-cu12                                         25.2.1\n",
            "cupy-cuda12x                                      13.3.0\n",
            "curl_cffi                                         0.11.1\n",
            "cuvs-cu12                                         25.2.1\n",
            "cvxopt                                            1.3.2\n",
            "cvxpy                                             1.6.5\n",
            "cycler                                            0.12.1\n",
            "cyipopt                                           1.5.0\n",
            "cymem                                             2.0.11\n",
            "Cython                                            3.0.12\n",
            "dask                                              2024.12.1\n",
            "dask-cuda                                         25.2.0\n",
            "dask-cudf-cu12                                    25.2.2\n",
            "dask-expr                                         1.1.21\n",
            "dataclasses-json                                  0.6.7\n",
            "dataproc-spark-connect                            0.7.4\n",
            "datascience                                       0.17.6\n",
            "datasets                                          3.6.0\n",
            "db-dtypes                                         1.4.3\n",
            "dbus-python                                       1.2.18\n",
            "debugpy                                           1.8.0\n",
            "decorator                                         4.4.2\n",
            "defusedxml                                        0.7.1\n",
            "Deprecated                                        1.2.18\n",
            "diffusers                                         0.33.1\n",
            "dill                                              0.3.7\n",
            "dirtyjson                                         1.0.8\n",
            "diskcache                                         5.6.3\n",
            "distributed                                       2024.12.1\n",
            "distributed-ucxx-cu12                             0.42.0\n",
            "distro                                            1.9.0\n",
            "dlib                                              19.24.6\n",
            "dm-tree                                           0.1.9\n",
            "docker-pycreds                                    0.4.0\n",
            "docstring_parser                                  0.16\n",
            "docutils                                          0.21.2\n",
            "dopamine_rl                                       4.1.2\n",
            "duckdb                                            1.2.2\n",
            "earthengine-api                                   1.5.15\n",
            "easydict                                          1.13\n",
            "editdistance                                      0.8.1\n",
            "eerepr                                            0.1.2\n",
            "einops                                            0.8.1\n",
            "en_core_web_sm                                    3.8.0\n",
            "entrypoints                                       0.4\n",
            "et_xmlfile                                        2.0.0\n",
            "etils                                             1.12.2\n",
            "etuples                                           0.3.9\n",
            "Farama-Notifications                              0.0.4\n",
            "fastai                                            2.7.19\n",
            "fastcore                                          1.7.29\n",
            "fastdownload                                      0.0.7\n",
            "fastjsonschema                                    2.21.1\n",
            "fastprogress                                      1.0.3\n",
            "fastrlock                                         0.8.3\n",
            "filelock                                          3.18.0\n",
            "filetype                                          1.2.0\n",
            "firebase-admin                                    6.8.0\n",
            "FlagEmbedding                                     1.3.5\n",
            "Flask                                             3.1.1\n",
            "flatbuffers                                       25.2.10\n",
            "flax                                              0.10.6\n",
            "folium                                            0.19.6\n",
            "fonttools                                         4.58.0\n",
            "frozendict                                        2.4.6\n",
            "frozenlist                                        1.6.0\n",
            "fsspec                                            2025.3.0\n",
            "future                                            1.0.0\n",
            "gast                                              0.6.0\n",
            "gcsfs                                             2025.3.2\n",
            "GDAL                                              3.8.4\n",
            "gdown                                             5.2.0\n",
            "geemap                                            0.35.3\n",
            "geocoder                                          1.38.1\n",
            "geographiclib                                     2.0\n",
            "geopandas                                         1.0.1\n",
            "geopy                                             2.4.1\n",
            "gin-config                                        0.5.0\n",
            "gitdb                                             4.0.12\n",
            "GitPython                                         3.1.44\n",
            "glob2                                             0.7\n",
            "google                                            2.0.3\n",
            "google-ai-generativelanguage                      0.6.15\n",
            "google-api-core                                   2.24.2\n",
            "google-api-python-client                          2.169.0\n",
            "google-auth                                       2.38.0\n",
            "google-auth-httplib2                              0.2.0\n",
            "google-auth-oauthlib                              1.2.2\n",
            "google-cloud-aiplatform                           1.93.1\n",
            "google-cloud-bigquery                             3.33.0\n",
            "google-cloud-bigquery-connection                  1.18.2\n",
            "google-cloud-bigquery-storage                     2.31.0\n",
            "google-cloud-core                                 2.4.3\n",
            "google-cloud-dataproc                             5.18.1\n",
            "google-cloud-datastore                            2.21.0\n",
            "google-cloud-firestore                            2.20.2\n",
            "google-cloud-functions                            1.20.3\n",
            "google-cloud-iam                                  2.19.0\n",
            "google-cloud-language                             2.17.1\n",
            "google-cloud-resource-manager                     1.14.2\n",
            "google-cloud-spanner                              3.54.0\n",
            "google-cloud-storage                              2.19.0\n",
            "google-cloud-translate                            3.20.2\n",
            "google-colab                                      1.0.0\n",
            "google-crc32c                                     1.7.1\n",
            "google-genai                                      1.16.1\n",
            "google-generativeai                               0.8.5\n",
            "google-pasta                                      0.2.0\n",
            "google-resumable-media                            2.7.2\n",
            "googleapis-common-protos                          1.70.0\n",
            "googledrivedownloader                             1.1.0\n",
            "graphviz                                          0.20.3\n",
            "greenlet                                          3.2.2\n",
            "griffe                                            1.7.3\n",
            "grpc-google-iam-v1                                0.14.2\n",
            "grpc-interceptor                                  0.15.4\n",
            "grpcio                                            1.71.0\n",
            "grpcio-status                                     1.71.0\n",
            "grpclib                                           0.4.8\n",
            "gspread                                           6.2.1\n",
            "gspread-dataframe                                 4.0.0\n",
            "gym                                               0.25.2\n",
            "gym-notices                                       0.0.8\n",
            "gymnasium                                         1.1.1\n",
            "h11                                               0.16.0\n",
            "h2                                                4.2.0\n",
            "h5netcdf                                          1.6.1\n",
            "h5py                                              3.13.0\n",
            "hdbscan                                           0.8.40\n",
            "hf_transfer                                       0.1.9\n",
            "highspy                                           1.10.0\n",
            "holidays                                          0.73\n",
            "holoviews                                         1.20.2\n",
            "hpack                                             4.1.0\n",
            "html5lib                                          1.1\n",
            "httpcore                                          1.0.9\n",
            "httpimport                                        1.4.1\n",
            "httplib2                                          0.22.0\n",
            "httpx                                             0.28.1\n",
            "huggingface-hub                                   0.31.4\n",
            "humanize                                          4.12.3\n",
            "hyperframe                                        6.1.0\n",
            "hyperopt                                          0.2.7\n",
            "ibis-framework                                    9.5.0\n",
            "idna                                              3.10\n",
            "ijson                                             3.4.0\n",
            "imageio                                           2.37.0\n",
            "imageio-ffmpeg                                    0.6.0\n",
            "imagesize                                         1.4.1\n",
            "imbalanced-learn                                  0.13.0\n",
            "immutabledict                                     4.2.1\n",
            "importlib_metadata                                8.7.0\n",
            "importlib_resources                               6.5.2\n",
            "imutils                                           0.5.4\n",
            "inflect                                           7.5.0\n",
            "iniconfig                                         2.1.0\n",
            "inscriptis                                        2.6.0\n",
            "intel-cmplr-lib-ur                                2025.1.1\n",
            "intel-openmp                                      2025.1.1\n",
            "ipyevents                                         2.0.2\n",
            "ipyfilechooser                                    0.6.0\n",
            "ipykernel                                         6.17.1\n",
            "ipyleaflet                                        0.19.2\n",
            "ipyparallel                                       8.8.0\n",
            "ipython                                           7.34.0\n",
            "ipython-genutils                                  0.2.0\n",
            "ipython-sql                                       0.5.0\n",
            "ipytree                                           0.2.2\n",
            "ipywidgets                                        7.7.1\n",
            "ir_datasets                                       0.5.10\n",
            "itsdangerous                                      2.2.0\n",
            "jaraco.classes                                    3.4.0\n",
            "jaraco.context                                    6.0.1\n",
            "jaraco.functools                                  4.1.0\n",
            "jax                                               0.5.2\n",
            "jax-cuda12-pjrt                                   0.5.1\n",
            "jax-cuda12-plugin                                 0.5.1\n",
            "jaxlib                                            0.5.1\n",
            "jeepney                                           0.9.0\n",
            "jieba                                             0.42.1\n",
            "Jinja2                                            3.1.6\n",
            "jiter                                             0.10.0\n",
            "joblib                                            1.5.0\n",
            "jsonpatch                                         1.33\n",
            "jsonpickle                                        4.1.0\n",
            "jsonpointer                                       3.0.0\n",
            "jsonschema                                        4.23.0\n",
            "jsonschema-specifications                         2025.4.1\n",
            "jupyter-client                                    6.1.12\n",
            "jupyter-console                                   6.1.0\n",
            "jupyter_core                                      5.7.2\n",
            "jupyter_kernel_gateway                            2.5.2\n",
            "jupyter-leaflet                                   0.19.2\n",
            "jupyter-server                                    1.16.0\n",
            "jupyterlab_pygments                               0.3.0\n",
            "jupyterlab_widgets                                3.0.15\n",
            "kaggle                                            1.7.4.5\n",
            "kagglehub                                         0.3.12\n",
            "keras                                             3.8.0\n",
            "keras-hub                                         0.18.1\n",
            "keras-nlp                                         0.18.1\n",
            "keyring                                           25.6.0\n",
            "keyrings.google-artifactregistry-auth             1.1.2\n",
            "kiwisolver                                        1.4.8\n",
            "langchain                                         0.3.25\n",
            "langchain-core                                    0.3.60\n",
            "langchain-text-splitters                          0.3.8\n",
            "langcodes                                         3.5.0\n",
            "langsmith                                         0.3.42\n",
            "language_data                                     1.3.0\n",
            "launchpadlib                                      1.10.16\n",
            "lazr.restfulclient                                0.14.4\n",
            "lazr.uri                                          1.0.6\n",
            "lazy_loader                                       0.4\n",
            "libclang                                          18.1.1\n",
            "libcudf-cu12                                      25.2.1\n",
            "libcugraph-cu12                                   25.2.0\n",
            "libcuml-cu12                                      25.2.1\n",
            "libcuvs-cu12                                      25.2.1\n",
            "libkvikio-cu12                                    25.2.1\n",
            "libpysal                                          4.13.0\n",
            "libraft-cu12                                      25.2.0\n",
            "librosa                                           0.11.0\n",
            "libucx-cu12                                       1.18.1\n",
            "libucxx-cu12                                      0.42.0\n",
            "lightgbm                                          4.5.0\n",
            "linkify-it-py                                     2.0.3\n",
            "llama-cloud                                       0.1.21\n",
            "llama-cloud-services                              0.6.15\n",
            "llama_cpp_python                                  0.3.7\n",
            "llama-index                                       0.12.37\n",
            "llama-index-agent-openai                          0.4.8\n",
            "llama-index-cli                                   0.4.1\n",
            "llama-index-core                                  0.12.37\n",
            "llama-index-embeddings-huggingface                0.5.4\n",
            "llama-index-embeddings-openai                     0.3.1\n",
            "llama-index-indices-managed-llama-cloud           0.7.0\n",
            "llama-index-llms-llama-cpp                        0.4.0\n",
            "llama-index-llms-openai                           0.3.44\n",
            "llama-index-multi-modal-llms-openai               0.4.3\n",
            "llama-index-postprocessor-flag-embedding-reranker 0.3.0\n",
            "llama-index-program-openai                        0.3.1\n",
            "llama-index-question-gen-openai                   0.3.0\n",
            "llama-index-readers-file                          0.4.8\n",
            "llama-index-readers-llama-parse                   0.4.0\n",
            "llama-parse                                       0.6.12\n",
            "llvmlite                                          0.43.0\n",
            "locket                                            1.0.0\n",
            "logical-unification                               0.4.6\n",
            "lxml                                              5.4.0\n",
            "lz4                                               4.4.4\n",
            "Mako                                              1.1.3\n",
            "marisa-trie                                       1.2.1\n",
            "Markdown                                          3.8\n",
            "markdown-it-py                                    3.0.0\n",
            "MarkupSafe                                        3.0.2\n",
            "marshmallow                                       3.26.1\n",
            "matplotlib                                        3.10.0\n",
            "matplotlib-inline                                 0.1.7\n",
            "matplotlib-venn                                   1.1.2\n",
            "mdit-py-plugins                                   0.4.2\n",
            "mdurl                                             0.1.2\n",
            "miniKanren                                        1.0.3\n",
            "missingno                                         0.5.2\n",
            "mistune                                           3.1.3\n",
            "mizani                                            0.13.5\n",
            "mkl                                               2025.0.1\n",
            "ml-dtypes                                         0.4.1\n",
            "mlxtend                                           0.23.4\n",
            "more-itertools                                    10.7.0\n",
            "moviepy                                           1.0.3\n",
            "mpmath                                            1.3.0\n",
            "msgpack                                           1.1.0\n",
            "multidict                                         6.4.4\n",
            "multipledispatch                                  1.0.0\n",
            "multiprocess                                      0.70.15\n",
            "multitasking                                      0.0.11\n",
            "murmurhash                                        1.0.12\n",
            "music21                                           9.3.0\n",
            "mypy_extensions                                   1.1.0\n",
            "namex                                             0.0.9\n",
            "narwhals                                          1.40.0\n",
            "natsort                                           8.4.0\n",
            "nbclassic                                         1.3.1\n",
            "nbclient                                          0.10.2\n",
            "nbconvert                                         7.16.6\n",
            "nbformat                                          5.10.4\n",
            "ndindex                                           1.10.0\n",
            "nest-asyncio                                      1.6.0\n",
            "networkx                                          3.4.2\n",
            "nibabel                                           5.3.2\n",
            "nltk                                              3.9.1\n",
            "notebook                                          6.5.7\n",
            "notebook_shim                                     0.2.4\n",
            "numba                                             0.60.0\n",
            "numba-cuda                                        0.2.0\n",
            "numexpr                                           2.10.2\n",
            "numpy                                             1.26.4\n",
            "nvidia-cublas-cu12                                12.4.5.8\n",
            "nvidia-cuda-cupti-cu12                            12.4.127\n",
            "nvidia-cuda-nvcc-cu12                             12.5.82\n",
            "nvidia-cuda-nvrtc-cu12                            12.4.127\n",
            "nvidia-cuda-runtime-cu12                          12.4.127\n",
            "nvidia-cudnn-cu12                                 9.1.0.70\n",
            "nvidia-cufft-cu12                                 11.2.1.3\n",
            "nvidia-curand-cu12                                10.3.5.147\n",
            "nvidia-cusolver-cu12                              11.6.1.9\n",
            "nvidia-cusparse-cu12                              12.3.1.170\n",
            "nvidia-cusparselt-cu12                            0.6.2\n",
            "nvidia-ml-py                                      12.575.51\n",
            "nvidia-nccl-cu12                                  2.21.5\n",
            "nvidia-nvcomp-cu12                                4.2.0.11\n",
            "nvidia-nvjitlink-cu12                             12.4.127\n",
            "nvidia-nvtx-cu12                                  12.4.127\n",
            "nvtx                                              0.2.11\n",
            "nx-cugraph-cu12                                   25.2.0\n",
            "oauth2client                                      4.1.3\n",
            "oauthlib                                          3.2.2\n",
            "omegaconf                                         2.3.0\n",
            "openai                                            1.81.0\n",
            "opencv-contrib-python                             4.11.0.86\n",
            "opencv-python                                     4.11.0.86\n",
            "opencv-python-headless                            4.11.0.86\n",
            "openpyxl                                          3.1.5\n",
            "opt_einsum                                        3.4.0\n",
            "optax                                             0.2.4\n",
            "optree                                            0.15.0\n",
            "orbax-checkpoint                                  0.11.13\n",
            "orjson                                            3.10.18\n",
            "osqp                                              1.0.4\n",
            "packaging                                         24.2\n",
            "pandas                                            2.2.2\n",
            "pandas-datareader                                 0.10.0\n",
            "pandas-gbq                                        0.29.0\n",
            "pandas-stubs                                      2.2.2.240909\n",
            "pandocfilters                                     1.5.1\n",
            "panel                                             1.7.0\n",
            "param                                             2.2.0\n",
            "parso                                             0.8.4\n",
            "parsy                                             2.1\n",
            "partd                                             1.4.2\n",
            "pathlib                                           1.0.1\n",
            "patsy                                             1.0.1\n",
            "peewee                                            3.18.1\n",
            "peft                                              0.15.2\n",
            "pexpect                                           4.9.0\n",
            "pickleshare                                       0.7.5\n",
            "pillow                                            11.2.1\n",
            "pip                                               24.1.2\n",
            "platformdirs                                      4.3.8\n",
            "plotly                                            5.24.1\n",
            "plotnine                                          0.14.5\n",
            "pluggy                                            1.6.0\n",
            "ply                                               3.11\n",
            "polars                                            1.21.0\n",
            "pooch                                             1.8.2\n",
            "portpicker                                        1.5.2\n",
            "preshed                                           3.0.9\n",
            "prettytable                                       3.16.0\n",
            "proglog                                           0.1.12\n",
            "progressbar2                                      4.5.0\n",
            "prometheus_client                                 0.22.0\n",
            "promise                                           2.3\n",
            "prompt_toolkit                                    3.0.51\n",
            "propcache                                         0.3.1\n",
            "prophet                                           1.1.6\n",
            "proto-plus                                        1.26.1\n",
            "protobuf                                          5.29.4\n",
            "psutil                                            5.9.5\n",
            "psycopg2                                          2.9.10\n",
            "ptyprocess                                        0.7.0\n",
            "py-cpuinfo                                        9.0.0\n",
            "py4j                                              0.10.9.7\n",
            "pyarrow                                           18.1.0\n",
            "pyasn1                                            0.6.1\n",
            "pyasn1_modules                                    0.4.2\n",
            "pycairo                                           1.28.0\n",
            "pycocotools                                       2.0.8\n",
            "pycparser                                         2.22\n",
            "pycryptodomex                                     3.23.0\n",
            "pydantic                                          2.11.4\n",
            "pydantic_core                                     2.33.2\n",
            "pydata-google-auth                                1.9.1\n",
            "pydot                                             3.0.4\n",
            "pydotplus                                         2.0.2\n",
            "PyDrive                                           1.3.1\n",
            "PyDrive2                                          1.21.3\n",
            "pyerfa                                            2.0.1.5\n",
            "pygame                                            2.6.1\n",
            "pygit2                                            1.18.0\n",
            "Pygments                                          2.19.1\n",
            "PyGObject                                         3.42.0\n",
            "PyJWT                                             2.10.1\n",
            "pylibcudf-cu12                                    25.2.1\n",
            "pylibcugraph-cu12                                 25.2.0\n",
            "pylibraft-cu12                                    25.2.0\n",
            "pymc                                              5.22.0\n",
            "pymystem3                                         0.2.0\n",
            "pynndescent                                       0.5.13\n",
            "pynvjitlink-cu12                                  0.6.0\n",
            "pynvml                                            12.0.0\n",
            "pyogrio                                           0.11.0\n",
            "pyomo                                             6.9.2\n",
            "PyOpenGL                                          3.1.9\n",
            "pyOpenSSL                                         24.2.1\n",
            "pyparsing                                         3.2.3\n",
            "pypdf                                             5.5.0\n",
            "pyperclip                                         1.9.0\n",
            "pyproj                                            3.7.1\n",
            "pyproject_hooks                                   1.2.0\n",
            "pyshp                                             2.3.1\n",
            "PySocks                                           1.7.1\n",
            "pyspark                                           3.5.1\n",
            "pytensor                                          2.30.3\n",
            "pytest                                            8.3.5\n",
            "python-apt                                        0.0.0\n",
            "python-box                                        7.3.2\n",
            "python-dateutil                                   2.9.0.post0\n",
            "python-dotenv                                     1.1.0\n",
            "python-louvain                                    0.16\n",
            "python-slugify                                    8.0.4\n",
            "python-snappy                                     0.7.3\n",
            "python-utils                                      3.9.1\n",
            "pytz                                              2025.2\n",
            "pyviz_comms                                       3.0.4\n",
            "PyWavelets                                        1.8.0\n",
            "PyYAML                                            6.0.2\n",
            "pyzmq                                             24.0.1\n",
            "raft-dask-cu12                                    25.2.0\n",
            "rapids-dask-dependency                            25.2.0\n",
            "ratelim                                           0.1.6\n",
            "referencing                                       0.36.2\n",
            "regex                                             2024.11.6\n",
            "requests                                          2.32.3\n",
            "requests-oauthlib                                 2.0.0\n",
            "requests-toolbelt                                 1.0.0\n",
            "requirements-parser                               0.9.0\n",
            "rich                                              13.9.4\n",
            "rmm-cu12                                          25.2.0\n",
            "roman-numerals-py                                 3.1.0\n",
            "rpds-py                                           0.25.1\n",
            "rpy2                                              3.5.17\n",
            "rsa                                               4.9.1\n",
            "safetensors                                       0.5.3\n",
            "scikit-image                                      0.25.2\n",
            "scikit-learn                                      1.6.1\n",
            "scipy                                             1.15.3\n",
            "scooby                                            0.10.1\n",
            "scs                                               3.2.7.post2\n",
            "seaborn                                           0.13.2\n",
            "SecretStorage                                     3.3.3\n",
            "Send2Trash                                        1.8.3\n",
            "sentence-transformers                             4.1.0\n",
            "sentencepiece                                     0.2.0\n",
            "sentry-sdk                                        2.29.1\n",
            "setproctitle                                      1.3.6\n",
            "setuptools                                        75.2.0\n",
            "shap                                              0.47.2\n",
            "shapely                                           2.1.1\n",
            "shellingham                                       1.5.4\n",
            "simple-parsing                                    0.1.7\n",
            "simplejson                                        3.20.1\n",
            "simsimd                                           6.2.1\n",
            "six                                               1.17.0\n",
            "sklearn-compat                                    0.1.3\n",
            "sklearn-pandas                                    2.2.0\n",
            "slicer                                            0.0.8\n",
            "smart-open                                        7.1.0\n",
            "smmap                                             5.0.2\n",
            "sniffio                                           1.3.1\n",
            "snowballstemmer                                   3.0.1\n",
            "sortedcontainers                                  2.4.0\n",
            "soundfile                                         0.13.1\n",
            "soupsieve                                         2.7\n",
            "soxr                                              0.5.0.post1\n",
            "spacy                                             3.8.6\n",
            "spacy-legacy                                      3.0.12\n",
            "spacy-loggers                                     1.0.5\n",
            "spanner-graph-notebook                            1.1.6\n",
            "Sphinx                                            8.2.3\n",
            "sphinxcontrib-applehelp                           2.0.0\n",
            "sphinxcontrib-devhelp                             2.0.0\n",
            "sphinxcontrib-htmlhelp                            2.1.0\n",
            "sphinxcontrib-jsmath                              1.0.1\n",
            "sphinxcontrib-qthelp                              2.0.0\n",
            "sphinxcontrib-serializinghtml                     2.0.0\n",
            "SQLAlchemy                                        2.0.41\n",
            "sqlglot                                           25.20.2\n",
            "sqlparse                                          0.5.3\n",
            "srsly                                             2.5.1\n",
            "stanio                                            0.5.1\n",
            "statsmodels                                       0.14.4\n",
            "stringzilla                                       3.12.5\n",
            "striprtf                                          0.0.26\n",
            "stumpy                                            1.13.0\n",
            "sympy                                             1.13.1\n",
            "tables                                            3.10.2\n",
            "tabulate                                          0.9.0\n",
            "tbb                                               2022.1.0\n",
            "tblib                                             3.1.0\n",
            "tcmlib                                            1.3.0\n",
            "tenacity                                          9.1.2\n",
            "tensorboard                                       2.18.0\n",
            "tensorboard-data-server                           0.7.2\n",
            "tensorflow                                        2.18.0\n",
            "tensorflow-datasets                               4.9.8\n",
            "tensorflow_decision_forests                       1.11.0\n",
            "tensorflow-hub                                    0.16.1\n",
            "tensorflow-io-gcs-filesystem                      0.37.1\n",
            "tensorflow-metadata                               1.17.1\n",
            "tensorflow-probability                            0.25.0\n",
            "tensorflow-text                                   2.18.1\n",
            "tensorstore                                       0.1.74\n",
            "termcolor                                         3.1.0\n",
            "terminado                                         0.18.1\n",
            "text-unidecode                                    1.3\n",
            "textblob                                          0.19.0\n",
            "tf_keras                                          2.18.0\n",
            "tf-slim                                           1.1.0\n",
            "thinc                                             8.3.6\n",
            "threadpoolctl                                     3.6.0\n",
            "tifffile                                          2025.5.21\n",
            "tiktoken                                          0.9.0\n",
            "timm                                              1.0.15\n",
            "tinycss2                                          1.4.0\n",
            "tokenizers                                        0.21.1\n",
            "toml                                              0.10.2\n",
            "toolz                                             0.12.1\n",
            "torch                                             2.6.0+cu124\n",
            "torchao                                           0.10.0\n",
            "torchaudio                                        2.6.0+cu124\n",
            "torchdata                                         0.11.0\n",
            "torchsummary                                      1.5.1\n",
            "torchtune                                         0.6.1\n",
            "torchvision                                       0.21.0+cu124\n",
            "tornado                                           6.4.2\n",
            "tqdm                                              4.67.1\n",
            "traitlets                                         5.7.1\n",
            "traittypes                                        0.2.1\n",
            "transformers                                      4.52.2\n",
            "trec-car-tools                                    2.6\n",
            "treelite                                          4.4.1\n",
            "treescope                                         0.1.9\n",
            "triton                                            3.2.0\n",
            "tsfresh                                           0.21.0\n",
            "tweepy                                            4.15.0\n",
            "typeguard                                         4.4.2\n",
            "typer                                             0.15.3\n",
            "types-pytz                                        2025.2.0.20250516\n",
            "types-setuptools                                  80.8.0.20250521\n",
            "typing_extensions                                 4.13.2\n",
            "typing-inspect                                    0.9.0\n",
            "typing-inspection                                 0.4.1\n",
            "tzdata                                            2025.2\n",
            "tzlocal                                           5.3.1\n",
            "uc-micro-py                                       1.0.3\n",
            "ucx-py-cu12                                       0.42.0\n",
            "ucxx-cu12                                         0.42.0\n",
            "umap-learn                                        0.5.7\n",
            "umf                                               0.10.0\n",
            "unlzw3                                            0.2.3\n",
            "uritemplate                                       4.1.1\n",
            "urllib3                                           2.4.0\n",
            "vega-datasets                                     0.9.0\n",
            "wadllib                                           1.3.6\n",
            "wandb                                             0.19.11\n",
            "warc3-wet                                         0.2.5\n",
            "warc3-wet-clueweb09                               0.2.5\n",
            "wasabi                                            1.1.3\n",
            "wcwidth                                           0.2.13\n",
            "weasel                                            0.4.1\n",
            "webcolors                                         24.11.1\n",
            "webencodings                                      0.5.1\n",
            "websocket-client                                  1.8.0\n",
            "websockets                                        15.0.1\n",
            "Werkzeug                                          3.1.3\n",
            "wheel                                             0.45.1\n",
            "widgetsnbextension                                3.6.10\n",
            "wordcloud                                         1.9.4\n",
            "wrapt                                             1.17.2\n",
            "wurlitzer                                         3.1.1\n",
            "xarray                                            2025.3.1\n",
            "xarray-einstats                                   0.8.0\n",
            "xgboost                                           2.1.4\n",
            "xlrd                                              2.0.1\n",
            "xxhash                                            3.5.0\n",
            "xyzservices                                       2025.4.0\n",
            "yarl                                              1.20.0\n",
            "ydf                                               0.12.0\n",
            "yellowbrick                                       1.5\n",
            "yfinance                                          0.2.61\n",
            "zict                                              3.0.0\n",
            "zipp                                              3.21.0\n",
            "zlib-state                                        0.1.9\n",
            "zstandard                                         0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "8fvwyTsP0M52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f5a67417-cb0f-4ee8-b831-90a469db05da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!CMAKE_ARGS=\"-DGGML_CUDA=on\" pip install llama-cpp-python==0.3.7 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu125 --upgrade --force-reinstall --no-cache-dir"
      ],
      "metadata": {
        "id": "19-qcaXIQ0bI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "ff9eb85e-8737-42da-da45-061647a05593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://abetlen.github.io/llama-cpp-python/whl/cu125\n",
            "Collecting llama-cpp-python==0.3.7\n",
            "  Downloading llama_cpp_python-0.3.7.tar.gz (66.7 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m66.7/66.7 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting typing-extensions>=4.5.0 (from llama-cpp-python==0.3.7)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting numpy>=1.20.0 (from llama-cpp-python==0.3.7)\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m266.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache>=5.6.1 (from llama-cpp-python==0.3.7)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting jinja2>=2.11.3 (from llama-cpp-python==0.3.7)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python==0.3.7)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m218.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m331.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m338.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m231.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.7-cp311-cp311-linux_x86_64.whl size=41082200 sha256=76ab6a3c2877cca81216684e5ca04020522db1388cd0c0252bf447bcd8032db7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9_qa511s/wheels/eb/82/79/ac77fcd49324b75ae6aa18e63a87cf9da4371a57e2cdc8dc03\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: typing-extensions, numpy, MarkupSafe, diskcache, jinja2, llama-cpp-python\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: diskcache\n",
            "    Found existing installation: diskcache 5.6.3\n",
            "    Uninstalling diskcache-5.6.3:\n",
            "      Successfully uninstalled diskcache-5.6.3\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: llama-cpp-python\n",
            "    Found existing installation: llama_cpp_python 0.3.7\n",
            "    Uninstalling llama_cpp_python-0.3.7:\n",
            "      Successfully uninstalled llama_cpp_python-0.3.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 diskcache-5.6.3 jinja2-3.1.6 llama-cpp-python-0.3.7 numpy-2.2.6 typing-extensions-4.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install numpy==1.26.4\n",
        "!pip install numpy==1.26.4 --force-reinstall --no-cache-dir"
      ],
      "metadata": {
        "id": "TtlNJadoUF5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6ed9c24-e632-4167-a499-8f5b7d9ff608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m336.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.6\n",
            "    Uninstalling numpy-2.2.6:\n",
            "      Successfully uninstalled numpy-2.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2UAfS56lZh-"
      },
      "source": [
        "## Implementation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "WluguhYZVhAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b6d1663-e81c-4b21-9e54-c16d8f88338a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GGPMIiOpF4b"
      },
      "source": [
        "## Load documents and build index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0hb-49phJj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "850598f3-e8c8-42c1-d329-5257d845219c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 11min 35s, sys: 6.1 s, total: 11min 41s\n",
            "Wall time: 11min 40s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3039"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "%%time\n",
        "documents = SimpleDirectoryReader(\"/content/drive/MyDrive/Courses/RAG/SDD\").load_data()\n",
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5czlXaU6gPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df9f352-2ba3-47f1-f6de-e3c0740cd683"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'page_label': '1',\n",
              " 'file_name': '537 Guide for Transformer Fire Safety Practices.pdf',\n",
              " 'file_path': '/content/drive/MyDrive/Courses/RAG/SDD/537 Guide for Transformer Fire Safety Practices.pdf',\n",
              " 'file_type': 'application/pdf',\n",
              " 'file_size': 4172940,\n",
              " 'creation_date': '2025-05-28',\n",
              " 'last_modified_date': '2018-02-14'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "documents[0].metadata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents[100]"
      ],
      "metadata": {
        "id": "e04jw1eRuLht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a50f69-2c9b-4575-c29a-63381eee9910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(id_='0b517d5d-fc66-40c7-bc0b-df769f891e67', embedding=None, metadata={'page_label': '101', 'file_name': '537 Guide for Transformer Fire Safety Practices.pdf', 'file_path': '/content/drive/MyDrive/Courses/RAG/SDD/537 Guide for Transformer Fire Safety Practices.pdf', 'file_type': 'application/pdf', 'file_size': 4172940, 'creation_date': '2025-05-28', 'last_modified_date': '2018-02-14'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Guide for Transformer Fire Safety Practices\\n92\\nFigure 42 illustrates how a fire barrier is used to protect two adjacent transformers. FM Global\\nadvises that the fire wall should ex tend at least 600mm horizontally and 300 mm vertically beyond\\nany transformer component that could be pressurized as a result of an electrical fault, including oil\\nfilled bushings. This is represented by the distance d and e respectively.\\nElevation view Plan view\\nFigure 42: Fire Barrier protecting two adjacent transformers.\\nd d\\ne\\nd d\\ne\\n2 Hour rated Fire Barrier\\nTransformer\\nContainment\\n2 Hour rated Fire Barrier\\n2 Hour rated Fire Barrier', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Llama3.1 8B 4bit GGUF ( 4.92 GB. )\n",
        "\n",
        "https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF"
      ],
      "metadata": {
        "id": "aqUERS2wsLx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def messages_to_prompt(messages):\n",
        "    prompt = \"\"\n",
        "    for message in messages:\n",
        "        if message.role == 'system':\n",
        "          prompt += f\"<|start_header_id|>system<|end_header_id|>{message.content}<|eot_id|>\\n\"\n",
        "          #prompt += f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>{message.content}<|eot_id|>\\n\"\n",
        "        elif message.role == 'user':\n",
        "          prompt += f\"<|start_header_id|>user<|end_header_id|>{message.content}<|eot_id|>\\n\"\n",
        "        elif message.role == 'assistant':\n",
        "          prompt += f\"<|start_header_id|>assistant<|end_header_id|>{message.content}<|eot_id|>\\n\"\n",
        "\n",
        "    # ensure we start with a system prompt, insert blank if needed\n",
        "    # if not prompt.startswith(\"<|begin_of_text|><|start_header_id|>system\"):\n",
        "    #     prompt = \"<|begin_of_text|>\" + prompt\n",
        "\n",
        "    # add final assistant prompt\n",
        "    prompt = prompt + \"<|start_header_id|>assistant<|end_header_id|><|eot_id|>\\n\"\n",
        "    return prompt\n",
        "\n",
        "def completion_to_prompt(completion):\n",
        "    return f\"<|start_header_id|>system<|end_header_id|><|eot_id|>\\n<|start_header_id|>user<|end_header_id|>{completion}<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
        "    #return f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|><|eot_id|>\\n<|start_header_id|>user<|end_header_id|>{completion}<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n\""
      ],
      "metadata": {
        "id": "sRpJ2bQczvOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  repo  huggingface\n",
        "model_url = \"https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf\"\n",
        "#model_url = 'https://huggingface.co/lmstudio-community/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q8_0.gguf'\n",
        "#model_url = 'https://huggingface.co/lmstudio-community/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_M.gguf'\n",
        "\n",
        "# From Google Drive\n",
        "#model_path = '/content/drive/MyDrive/BaseModel/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf'\n",
        "\n",
        "from llama_index.llms.llama_cpp import LlamaCPP\n",
        "\n",
        "llm = LlamaCPP(\n",
        "    model_url=model_url,\n",
        "    model_path=None,\n",
        "    temperature=0.1,\n",
        "    context_window=8192,\n",
        "    max_new_tokens=1024, #  1024 bytes\n",
        "    generate_kwargs={},\n",
        "    model_kwargs={\n",
        "        \"repetition-penalty\":1.4,\n",
        "        \"no_repeat_ngram_size\": 4,\n",
        "         #\"response_format\": { \"type\": \"json_object\" },\n",
        "        \"n_gpu_layers\": -1\n",
        "        },\n",
        "    #model_kwargs={\"n_gpu_layers\": 33},\n",
        "    messages_to_prompt=messages_to_prompt,\n",
        "    completion_to_prompt=completion_to_prompt,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "mS0R2fsLlBYl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e23b158-67de-4aea-c835-784cf1767a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
            "ggml_cuda_init: found 1 CUDA devices:\n",
            "  Device 0: NVIDIA L4, compute capability 8.9, VMM: yes\n",
            "llama_model_load_from_file_impl: using device CUDA0 (NVIDIA L4) - 22503 MiB free\n",
            "llama_model_loader: loaded meta data with 33 key-value pairs and 292 tensors from /tmp/llama_index/models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Meta Llama 3.1 8B Instruct\n",
            "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
            "llama_model_loader: - kv   4:                           general.basename str              = Meta-Llama-3.1\n",
            "llama_model_loader: - kv   5:                         general.size_label str              = 8B\n",
            "llama_model_loader: - kv   6:                            general.license str              = llama3.1\n",
            "llama_model_loader: - kv   7:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
            "llama_model_loader: - kv   8:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\n",
            "llama_model_loader: - kv   9:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv  10:                       llama.context_length u32              = 131072\n",
            "llama_model_loader: - kv  11:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  17:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\" \", \" \", \" \", \"...\n",
            "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009\n",
            "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
            "llama_model_loader: - kv  28:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  29:                      quantize.imatrix.file str              = /models_out/Meta-Llama-3.1-8B-Instruc...\n",
            "llama_model_loader: - kv  30:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
            "llama_model_loader: - kv  31:             quantize.imatrix.entries_count i32              = 224\n",
            "llama_model_loader: - kv  32:              quantize.imatrix.chunks_count i32              = 125\n",
            "llama_model_loader: - type  f32:   66 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 4.58 GiB (4.89 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 2\n",
            "load: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
            "load: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
            "load: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
            "load: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
            "load: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
            "load: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
            "load: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
            "load: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
            "load: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
            "load: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
            "load: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
            "load: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
            "load: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
            "load: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
            "load: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
            "load: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
            "load: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
            "load: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
            "load: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
            "load: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
            "load: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
            "load: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
            "load: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
            "load: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
            "load: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
            "load: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
            "load: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
            "load: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
            "load: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
            "load: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
            "load: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
            "load: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
            "load: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
            "load: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
            "load: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
            "load: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
            "load: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
            "load: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
            "load: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
            "load: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
            "load: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
            "load: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
            "load: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
            "load: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
            "load: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
            "load: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
            "load: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
            "load: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
            "load: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
            "load: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
            "load: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
            "load: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
            "load: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
            "load: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
            "load: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
            "load: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
            "load: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
            "load: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
            "load: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
            "load: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
            "load: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
            "load: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
            "load: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
            "load: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
            "load: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
            "load: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
            "load: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
            "load: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
            "load: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
            "load: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
            "load: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
            "load: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
            "load: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
            "load: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
            "load: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
            "load: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
            "load: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
            "load: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
            "load: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
            "load: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
            "load: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
            "load: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
            "load: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
            "load: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
            "load: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
            "load: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
            "load: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
            "load: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
            "load: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
            "load: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
            "load: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
            "load: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
            "load: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
            "load: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
            "load: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
            "load: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
            "load: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
            "load: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
            "load: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
            "load: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
            "load: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
            "load: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
            "load: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
            "load: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
            "load: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
            "load: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
            "load: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
            "load: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
            "load: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
            "load: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
            "load: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
            "load: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
            "load: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
            "load: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
            "load: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
            "load: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
            "load: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
            "load: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
            "load: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
            "load: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
            "load: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
            "load: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
            "load: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
            "load: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
            "load: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
            "load: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
            "load: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
            "load: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
            "load: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
            "load: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
            "load: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
            "load: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
            "load: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
            "load: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
            "load: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
            "load: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
            "load: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
            "load: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
            "load: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
            "load: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
            "load: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
            "load: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
            "load: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
            "load: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
            "load: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
            "load: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
            "load: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
            "load: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
            "load: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
            "load: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
            "load: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
            "load: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
            "load: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
            "load: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
            "load: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
            "load: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
            "load: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
            "load: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
            "load: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
            "load: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
            "load: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
            "load: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
            "load: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
            "load: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
            "load: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
            "load: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
            "load: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
            "load: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
            "load: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
            "load: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
            "load: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
            "load: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
            "load: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
            "load: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
            "load: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
            "load: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
            "load: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
            "load: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
            "load: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
            "load: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
            "load: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
            "load: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
            "load: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
            "load: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
            "load: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
            "load: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
            "load: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
            "load: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
            "load: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
            "load: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
            "load: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
            "load: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
            "load: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
            "load: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
            "load: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
            "load: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
            "load: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
            "load: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
            "load: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
            "load: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
            "load: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
            "load: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
            "load: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
            "load: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
            "load: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
            "load: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
            "load: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
            "load: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
            "load: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
            "load: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
            "load: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
            "load: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
            "load: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
            "load: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
            "load: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
            "load: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
            "load: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
            "load: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
            "load: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
            "load: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
            "load: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
            "load: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
            "load: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
            "load: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
            "load: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
            "load: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
            "load: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
            "load: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
            "load: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
            "load: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
            "load: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
            "load: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
            "load: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
            "load: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
            "load: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
            "load: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
            "load: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
            "load: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
            "load: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
            "load: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
            "load: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
            "load: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
            "load: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
            "load: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
            "load: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
            "load: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
            "load: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
            "load: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
            "load: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
            "load: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
            "load: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
            "load: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
            "load: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
            "load: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
            "load: special tokens cache size = 256\n",
            "load: token to piece cache size = 0.7999 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 131072\n",
            "print_info: n_embd           = 4096\n",
            "print_info: n_layer          = 32\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 4\n",
            "print_info: n_embd_k_gqa     = 1024\n",
            "print_info: n_embd_v_gqa     = 1024\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: n_ff             = 14336\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 500000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 131072\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: ssm_d_conv       = 0\n",
            "print_info: ssm_d_inner      = 0\n",
            "print_info: ssm_d_state      = 0\n",
            "print_info: ssm_dt_rank      = 0\n",
            "print_info: ssm_dt_b_c_rms   = 0\n",
            "print_info: model type       = 8B\n",
            "print_info: model params     = 8.03 B\n",
            "print_info: general.name     = Meta Llama 3.1 8B Instruct\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 128256\n",
            "print_info: n_merges         = 280147\n",
            "print_info: BOS token        = 128000 '<|begin_of_text|>'\n",
            "print_info: EOS token        = 128009 '<|eot_id|>'\n",
            "print_info: EOT token        = 128009 '<|eot_id|>'\n",
            "print_info: EOM token        = 128008 '<|eom_id|>'\n",
            "print_info: LF token         = 128 ''\n",
            "print_info: EOG token        = 128008 '<|eom_id|>'\n",
            "print_info: EOG token        = 128009 '<|eot_id|>'\n",
            "print_info: max token length = 256\n",
            "load_tensors: layer   0 assigned to device CUDA0\n",
            "load_tensors: layer   1 assigned to device CUDA0\n",
            "load_tensors: layer   2 assigned to device CUDA0\n",
            "load_tensors: layer   3 assigned to device CUDA0\n",
            "load_tensors: layer   4 assigned to device CUDA0\n",
            "load_tensors: layer   5 assigned to device CUDA0\n",
            "load_tensors: layer   6 assigned to device CUDA0\n",
            "load_tensors: layer   7 assigned to device CUDA0\n",
            "load_tensors: layer   8 assigned to device CUDA0\n",
            "load_tensors: layer   9 assigned to device CUDA0\n",
            "load_tensors: layer  10 assigned to device CUDA0\n",
            "load_tensors: layer  11 assigned to device CUDA0\n",
            "load_tensors: layer  12 assigned to device CUDA0\n",
            "load_tensors: layer  13 assigned to device CUDA0\n",
            "load_tensors: layer  14 assigned to device CUDA0\n",
            "load_tensors: layer  15 assigned to device CUDA0\n",
            "load_tensors: layer  16 assigned to device CUDA0\n",
            "load_tensors: layer  17 assigned to device CUDA0\n",
            "load_tensors: layer  18 assigned to device CUDA0\n",
            "load_tensors: layer  19 assigned to device CUDA0\n",
            "load_tensors: layer  20 assigned to device CUDA0\n",
            "load_tensors: layer  21 assigned to device CUDA0\n",
            "load_tensors: layer  22 assigned to device CUDA0\n",
            "load_tensors: layer  23 assigned to device CUDA0\n",
            "load_tensors: layer  24 assigned to device CUDA0\n",
            "load_tensors: layer  25 assigned to device CUDA0\n",
            "load_tensors: layer  26 assigned to device CUDA0\n",
            "load_tensors: layer  27 assigned to device CUDA0\n",
            "load_tensors: layer  28 assigned to device CUDA0\n",
            "load_tensors: layer  29 assigned to device CUDA0\n",
            "load_tensors: layer  30 assigned to device CUDA0\n",
            "load_tensors: layer  31 assigned to device CUDA0\n",
            "load_tensors: layer  32 assigned to device CUDA0\n",
            "load_tensors: tensor 'token_embd.weight' (q4_K) (and 0 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
            "load_tensors: offloading 32 repeating layers to GPU\n",
            "load_tensors: offloading output layer to GPU\n",
            "load_tensors: offloaded 33/33 layers to GPU\n",
            "load_tensors:        CUDA0 model buffer size =  4403.49 MiB\n",
            "load_tensors:   CPU_Mapped model buffer size =   281.81 MiB\n",
            "llama_init_from_model: n_seq_max     = 1\n",
            "llama_init_from_model: n_ctx         = 8192\n",
            "llama_init_from_model: n_ctx_per_seq = 8192\n",
            "llama_init_from_model: n_batch       = 512\n",
            "llama_init_from_model: n_ubatch      = 512\n",
            "llama_init_from_model: flash_attn    = 0\n",
            "llama_init_from_model: freq_base     = 500000.0\n",
            "llama_init_from_model: freq_scale    = 1\n",
            "llama_init_from_model: n_ctx_per_seq (8192) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "llama_kv_cache_init: kv_size = 8192, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
            "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =  1024.00 MiB\n",
            "llama_init_from_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
            "llama_init_from_model:  CUDA_Host  output buffer size =     0.49 MiB\n",
            "llama_init_from_model:      CUDA0 compute buffer size =   560.00 MiB\n",
            "llama_init_from_model:  CUDA_Host compute buffer size =    24.01 MiB\n",
            "llama_init_from_model: graph nodes  = 1030\n",
            "llama_init_from_model: graph splits = 2\n",
            "CUDA : ARCHS = 890 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | AVX512 = 1 | AVX512_VNNI = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "Model metadata: {'quantize.imatrix.entries_count': '224', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'quantize.imatrix.chunks_count': '125', 'quantize.imatrix.file': '/models_out/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct.imatrix', 'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- set date_string = \"26 Jul 2024\" %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if builtin_tools is defined or tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{- \"Tools: \" + builtin_tools | reject(\\'equalto\\', \\'code_interpreter\\') | join(\", \") + \"\\\\n\\\\n\"}}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\\n                {{- arg_name + \\'=\"\\' + arg_val + \\'\"\\' }}\\n                {%- if not loop.last %}\\n                    {{- \", \" }}\\n                {%- endif %}\\n                {%- endfor %}\\n            {{- \")\" }}\\n        {%- else  %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n            {{- \\'\"parameters\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \"}\" }}\\n        {%- endif %}\\n        {%- if builtin_tools is defined %}\\n            {#- This means we\\'re in ipython mode #}\\n            {{- \"<|eom_id|>\" }}\\n        {%- else %}\\n            {{- \"<|eot_id|>\" }}\\n        {%- endif %}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '15', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '500000.000000', 'general.architecture': 'llama', 'general.basename': 'Meta-Llama-3.1', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '131072', 'general.name': 'Meta Llama 3.1 8B Instruct', 'general.finetune': 'Instruct', 'general.type': 'model', 'general.size_label': '8B', 'general.license': 'llama3.1', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8'}\n",
            "Available chat formats from metadata: chat_template.default\n",
            "Using gguf chat template: {{- bos_token }}\n",
            "{%- if custom_tools is defined %}\n",
            "    {%- set tools = custom_tools %}\n",
            "{%- endif %}\n",
            "{%- if not tools_in_user_message is defined %}\n",
            "    {%- set tools_in_user_message = true %}\n",
            "{%- endif %}\n",
            "{%- if not date_string is defined %}\n",
            "    {%- set date_string = \"26 Jul 2024\" %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
            "{%- if messages[0]['role'] == 'system' %}\n",
            "    {%- set system_message = messages[0]['content']|trim %}\n",
            "    {%- set messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set system_message = \"\" %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- System message + builtin tools #}\n",
            "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
            "{%- if builtin_tools is defined or tools is not none %}\n",
            "    {{- \"Environment: ipython\\n\" }}\n",
            "{%- endif %}\n",
            "{%- if builtin_tools is defined %}\n",
            "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n",
            "{%- endif %}\n",
            "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
            "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
            "{%- if tools is not none and not tools_in_user_message %}\n",
            "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\\n\\n\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\\n\\n\" }}\n",
            "    {%- endfor %}\n",
            "{%- endif %}\n",
            "{{- system_message }}\n",
            "{{- \"<|eot_id|>\" }}\n",
            "\n",
            "{#- Custom tools are passed in a user message with some extra guidance #}\n",
            "{%- if tools_in_user_message and not tools is none %}\n",
            "    {#- Extract the first user message so we can plug it in here #}\n",
            "    {%- if messages | length != 0 %}\n",
            "        {%- set first_user_message = messages[0]['content']|trim %}\n",
            "        {%- set messages = messages[1:] %}\n",
            "    {%- else %}\n",
            "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
            "{%- endif %}\n",
            "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
            "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
            "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\\n\\n\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\\n\\n\" }}\n",
            "    {%- endfor %}\n",
            "    {{- first_user_message + \"<|eot_id|>\"}}\n",
            "{%- endif %}\n",
            "\n",
            "{%- for message in messages %}\n",
            "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
            "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
            "    {%- elif 'tool_calls' in message %}\n",
            "        {%- if not message.tool_calls|length == 1 %}\n",
            "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
            "        {%- endif %}\n",
            "        {%- set tool_call = message.tool_calls[0].function %}\n",
            "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
            "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
            "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
            "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
            "                {%- if not loop.last %}\n",
            "                    {{- \", \" }}\n",
            "                {%- endif %}\n",
            "                {%- endfor %}\n",
            "            {{- \")\" }}\n",
            "        {%- else  %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
            "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
            "            {{- '\"parameters\": ' }}\n",
            "            {{- tool_call.arguments | tojson }}\n",
            "            {{- \"}\" }}\n",
            "        {%- endif %}\n",
            "        {%- if builtin_tools is defined %}\n",
            "            {#- This means we're in ipython mode #}\n",
            "            {{- \"<|eom_id|>\" }}\n",
            "        {%- else %}\n",
            "            {{- \"<|eot_id|>\" }}\n",
            "        {%- endif %}\n",
            "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
            "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
            "        {%- if message.content is mapping or message.content is iterable %}\n",
            "            {{- message.content | tojson }}\n",
            "        {%- else %}\n",
            "            {{- message.content }}\n",
            "        {%- endif %}\n",
            "        {{- \"<|eot_id|>\" }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "{%- if add_generation_prompt %}\n",
            "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
            "{%- endif %}\n",
            "\n",
            "Using chat eos_token: <|eot_id|>\n",
            "Using chat bos_token: <|begin_of_text|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm"
      ],
      "metadata": {
        "id": "p5XDCFomQDyG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dddd935-0803-432c-e155-ee6c30ad2c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaCPP(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7efebbd01710>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x7efebce63ec0>, completion_to_prompt=<function completion_to_prompt at 0x7efebce60180>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, model_url='https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf', model_path='/tmp/llama_index/models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf', temperature=0.1, max_new_tokens=1024, context_window=8192, generate_kwargs={'temperature': 0.1, 'max_tokens': 1024}, model_kwargs={'n_ctx': 8192, 'verbose': True, 'repetition-penalty': 1.4, 'no_repeat_ngram_size': 4, 'n_gpu_layers': -1}, verbose=True)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Model ( without RAG )"
      ],
      "metadata": {
        "id": "03Z2pdPhEP1O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMsRrw9s91wW"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# llm.generate_kwargs={'temperature': 0.1, 'max_tokens': 512}\n",
        "\n",
        "# response = llm.complete(\"   \" )\n",
        "# display(Markdown(f\"{response.text}\"))\n",
        "# len(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "llm.generate_kwargs={'temperature': 0.1, 'max_tokens': 1024}\n",
        "stream_response = llm.stream_complete(\n",
        "    \"   \"\n",
        ")\n",
        "for t in stream_response:\n",
        "    print(t.delta, end=\"\")\n",
        "print()"
      ],
      "metadata": {
        "id": "O6E0hCwpRNEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e38d3f0b-1202-4673-ed26-18b491ddeea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "\n",
            "1.  (Hatha Yoga) -  \n",
            "\n",
            "2.  (Bhakti Yoga) -  \n",
            "\n",
            "3.  (Jnana Yoga) -  \n",
            "\n",
            "4.  (Kundalini Yoga) -  \n",
            "\n",
            "5.  (Raja Yoga) -  \n",
            "\n",
            "6.  (Karma Yoga) -  \n",
            "\n",
            "7.  (Mantra Yoga) -  \n",
            "\n",
            "8.  (Laya Yoga) -  \n",
            "\n",
            "9.  (Natha Yoga) -  \n",
            "\n",
            "10.  (Vijnana Yoga) -  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =     212.22 ms\n",
            "llama_perf_context_print: prompt eval time =     211.89 ms /    41 tokens (    5.17 ms per token,   193.50 tokens per second)\n",
            "llama_perf_context_print:        eval time =   12351.23 ms /   570 runs   (   21.67 ms per token,    46.15 tokens per second)\n",
            "llama_perf_context_print:       total time =   13539.87 ms /   611 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CPU times: user 13.5 s, sys: 116 ms, total: 13.6 s\n",
            "Wall time: 13.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "LsAbegtc43F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stream Response"
      ],
      "metadata": {
        "id": "hNTcEoQx07U1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# llm.generate_kwargs={'temperature': 0.1, 'max_tokens': 1024}\n",
        "# stream_response = llm.stream_complete(\n",
        "#     \"   \"\n",
        "# )\n",
        "# for t in stream_response:\n",
        "#     print(t.delta, end=\"\" , flush=True)\n",
        "# print()"
      ],
      "metadata": {
        "id": "TxO-NNxP027Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# from llama_index.core.llms import ChatMessage\n",
        "\n",
        "# messages = [\n",
        "#     ChatMessage(role=\"system\", content=\"You are an AI assistant that answers questions in Thai language\"),\n",
        "#     ChatMessage(role=\"user\", content=\"   \"),\n",
        "# ]\n",
        "# stream_response = llm.stream_chat(messages)\n",
        "\n",
        "# for t in stream_response:\n",
        "#     print(t.delta, end=\"\" , flush=True)\n",
        "# print()"
      ],
      "metadata": {
        "id": "iIMBgAprIBt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Model"
      ],
      "metadata": {
        "id": "td4o6tXpETUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-m3\")                      # size 8192\n",
        "#embed_model = HuggingFaceEmbedding(model_name=\"intfloat/multilingual-e5-large\")  # size 1024\n",
        "\n",
        "# local file\n",
        "#embed_model = HuggingFaceEmbedding(model_name='/content/drive/MyDrive/EmbeddingModel/bge-m3')"
      ],
      "metadata": {
        "id": "BPCnD1OmmZTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.chunk_size    = 3840\n",
        "Settings.chunk_overlap = 256\n",
        "Settings.llm = llm\n",
        "Settings.embed_model   = embed_model"
      ],
      "metadata": {
        "id": "PMZAXVu4TwMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing"
      ],
      "metadata": {
        "id": "x6coLAhaEiGM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4t_HpOAZ3qL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148,
          "referenced_widgets": [
            "cbc559f9058c457eb8b1daa325319636",
            "812f579aa68a4d008883a5d02f236770",
            "10e0d888b6754e25976219b9bfe9ad82",
            "45ce1610b1fc4c90bca5a2112cf07e07",
            "0bd35319d3ed452d8aa8cd1f6c389343",
            "8d86021fa52540f9b93883bd679dd335",
            "d10282d1e87442588f58e0876a53ce62",
            "7681f9dc7c5f401eb553b6e9528cc5e2",
            "31fb31c0cb6442f482bef234266df26c",
            "ea1106b1b289421f85a8cf6592ce8e1a",
            "5505d5b11dea4b56b5e4980740802947",
            "ec69b3b922ec4c84b8efa67cf377f002",
            "db2dabbdb3f74c6dbc33da2a2755a828",
            "cfbc0c7a6291437fb9619c4faf9e11e6",
            "6bbb2da5605545e884623e5180e2802f",
            "c535e9d97bd342dc80630d982b222da6",
            "1e107b5c4cb64562ba931f68602c18a6",
            "6023ef11b9284d0fa325bf3023854989",
            "a03d48901eb9428297a8af2d66770c1d",
            "1459e943754e467c962c05520d7d57e0",
            "48b0ff3b29c14709a617208af54e34b6",
            "b859b06f01874309a09a9111382e4358",
            "47218e5fece645e392f2024c794b7948",
            "ccd3446ba6c8472c8ef390908878774a",
            "1f15914637004334bafdea1ba972f6ba",
            "6e58d8863b214fac90472944d40501fa",
            "75bb84f218824af594bb1459bd402f6b",
            "0076d54f187b4ccc8d37037e7143f1aa",
            "60fde0d1762e42d9a9af76268f49bfd4",
            "a817d115a7794764ae33dc5bf2f3416c",
            "f695330864b14abcbea95017447bf976",
            "6dff0831f819495093d96fa7c8ab2932",
            "4cf73b368ecf440f90804d82b1cdab63"
          ]
        },
        "outputId": "1c2bc540-ca12-4ad2-bdc4-17a3644f503b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/3039 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbc559f9058c457eb8b1daa325319636"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec69b3b922ec4c84b8efa67cf377f002"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/991 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47218e5fece645e392f2024c794b7948"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4min 27s, sys: 874 ms, total: 4min 28s\n",
            "Wall time: 4min 19s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "index = VectorStoreIndex.from_documents(documents ,show_progress=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywx4UsvIo1SL"
      },
      "source": [
        "## Query\n",
        "Start querying by getting the default query engine\n",
        "https://docs.llamaindex.ai/en/stable/module_guides/querying/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from llama_index.core import PromptTemplate\n",
        "\n",
        "# template = (\n",
        "#     \"Context information is below.\\n\"\n",
        "#     \"---------------------\\n\"\n",
        "#     \"{context_str}\\n\"\n",
        "#     \"---------------------\\n\"\n",
        "#     \"Given the context information and not prior knowledge, \"\n",
        "#     \"answer the query in Thai language.\\n\"\n",
        "#     \"Query: {query_str}\\n\"\n",
        "#     \"Answer: \"\n",
        "# )\n",
        "# prompt_template = PromptTemplate(template)"
      ],
      "metadata": {
        "id": "dGqciUT7RyIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=20,\n",
        "    verbose=True,\n",
        "    streaming=True,\n",
        "    #text_qa_template=prompt_template,\n",
        ")\n",
        "\n",
        "response = query_engine.query(\"\")\n",
        "response.print_response_stream()\n",
        "\n",
        "# display(Markdown(f\"{response}\"))\n",
        "# clear_gpu_memory()"
      ],
      "metadata": {
        "id": "BJXpe50FziVY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19a44245-ded3-477a-83dd-52edd0366a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 9 prefix-match hit, remaining 7071 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4419.93 ms\n",
            "llama_perf_context_print: prompt eval time =    4890.47 ms /  7071 tokens (    0.69 ms per token,  1445.87 tokens per second)\n",
            "llama_perf_context_print:        eval time =   11333.41 ms /   412 runs   (   27.51 ms per token,    36.35 tokens per second)\n",
            "llama_perf_context_print:       total time =   16892.22 ms /  7483 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 6905 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4419.93 ms\n",
            "llama_perf_context_print: prompt eval time =    4770.25 ms /  6905 tokens (    0.69 ms per token,  1447.51 tokens per second)\n",
            "llama_perf_context_print:        eval time =   23645.02 ms /   858 runs   (   27.56 ms per token,    36.29 tokens per second)\n",
            "llama_perf_context_print:       total time =   30195.64 ms /  7763 tokens\n",
            "Llama.generate: 33 prefix-match hit, remaining 2221 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4419.93 ms\n",
            "llama_perf_context_print: prompt eval time =    1107.06 ms /  2221 tokens (    0.50 ms per token,  2006.22 tokens per second)\n",
            "llama_perf_context_print:        eval time =   10978.10 ms /   467 runs   (   23.51 ms per token,    42.54 tokens per second)\n",
            "llama_perf_context_print:       total time =   12874.46 ms /  2688 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 6222 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided context, the refined answer to the query \"\" (How to prevent lightning strikes) is:\n",
            "\n",
            "\n",
            "\n",
            "1.    (air terminal)   (mast)\n",
            "2. \n",
            "3. , , , , , \n",
            "4.  (metallic)   (Faraday) \n",
            "5. \n",
            "\n",
            "   (catenary system)   (shipboard lightning protection system) \n",
            "\n",
            "  \n",
            "\n",
            "  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    4419.93 ms\n",
            "llama_perf_context_print: prompt eval time =    4103.33 ms /  6222 tokens (    0.66 ms per token,  1516.33 tokens per second)\n",
            "llama_perf_context_print:        eval time =   14799.77 ms /   548 runs   (   27.01 ms per token,    37.03 tokens per second)\n",
            "llama_perf_context_print:       total time =   20272.95 ms /  6770 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRJ4T8jj4WMU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a136ca20-8970-465a-feff-e6c17304114b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of source nodes: 2\n",
            "Node Score: 0.623294117668057\n",
            "{'page_label': '10', 'file_name': '_21-.pdf', 'file_path': '/content/drive/MyDrive/Courses/RAG/C2_Llama3x-RAG-Workshop/dataset/Tri45-5files/_21-.pdf', 'file_type': 'application/pdf', 'file_size': 1112869, 'creation_date': '2024-12-12', 'last_modified_date': '2024-07-07'}\n",
            "Node Score: 0.5962243557236705\n",
            "{'page_label': '11', 'file_name': '_21-.pdf', 'file_path': '/content/drive/MyDrive/Courses/RAG/C2_Llama3x-RAG-Workshop/dataset/Tri45-5files/_21-.pdf', 'file_type': 'application/pdf', 'file_size': 1112869, 'creation_date': '2024-12-12', 'last_modified_date': '2024-07-07'}\n"
          ]
        }
      ],
      "source": [
        "# Print the number of source nodes\n",
        "num_source_nodes = len(response.source_nodes)\n",
        "print(f\"Number of source nodes: {num_source_nodes}\")\n",
        "\n",
        "# Loop over source nodes and print meta data\n",
        "for s in response.source_nodes:\n",
        "    print(f\"Node Score: {s.score}\")\n",
        "    print(s.node.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.response_txt"
      ],
      "metadata": {
        "id": "cN05L5ks_DY4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "54b712a5-7135-45be-dbd6-6e98a3892ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'     4 '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "qIfK-Mpu_F_u",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44fd41bc-d40e-40bd-fbfa-dfe49b39dcff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StreamingResponse(response_gen=<generator object stream_completion_response_to_tokens.<locals>.gen at 0x7d3e9f095e50>, source_nodes=[NodeWithScore(node=TextNode(id_='9157334f-e405-4cf5-ae51-dad504191b28', embedding=None, metadata={'page_label': '10', 'file_name': '_21-.pdf', 'file_path': '/content/drive/MyDrive/Courses/RAG/C2_Llama3x-RAG-Workshop/dataset/Tri45-5files/_21-.pdf', 'file_type': 'application/pdf', 'file_size': 1112869, 'creation_date': '2024-12-12', 'last_modified_date': '2024-07-07'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='fbbab046-4bb1-4348-a189-fab23435ef1a', node_type='4', metadata={'page_label': '10', 'file_name': '_21-.pdf', 'file_path': '/content/drive/MyDrive/Courses/RAG/C2_Llama3x-RAG-Workshop/dataset/Tri45-5files/_21-.pdf', 'file_type': 'application/pdf', 'file_size': 1112869, 'creation_date': '2024-12-12', 'last_modified_date': '2024-07-07'}, hash='9ed1b89a0c41ef3baf6334f6da991047c2f447d55a91327ac1e60406b000ac42')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='\\uf701 \\uf70a    - \\uf70b 10 \\n  \\uf70a \\uf712   \\n \\uf70a  \\n \\uf70a\\uf70b    \\n \\uf70a \\uf70a     \\uf712  \\n\\uf712  \\uf70a\\uf70a\\uf70b     \\n\\uf70a  \\uf712 \\uf70a\\uf70b   \\n  \\uf70a   \\uf712 \\uf70a\\uf70b  \\n\\uf70a\\uf70b   \\uf70a \\uf70a     \\n  \\uf712 \\uf70b\\uf70b \\uf712 \\n\\uf70b \\uf712\\uf70b\\uf70a  \\uf70e\\uf712   \\n\\uf70a  \\uf70a \\uf70b\\uf70a     \\n\\uf70a  \\n           \\uf712   \\n    \\n   \\n   \\uf712  \\uf70a\\uf70b \\n   \\uf70a \\uf712  \\n\\uf70b      \\uf70a \\uf712 \\n    \\uf70a  \\n \\uf70a\\uf70b   \\n  \\uf70a\\uf70a \\uf70a\\uf712 \\n \\uf712   \\uf70a\\uf70b \\n   \\uf70a   \\uf712  \\n\\uf70b    \\uf70a \\n\\uf712    \\uf70a \\n  \\uf70a\\uf70b   \\n \\uf70a\\uf70a \\uf70a  \\n \\uf712 \\uf712 ', mimetype='text/plain', start_char_idx=0, end_char_idx=2267, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.623294117668057), NodeWithScore(node=TextNode(id_='04447e70-06cc-442e-9754-ac54014d783f', embedding=None, metadata={'page_label': '11', 'file_name': '_21-.pdf', 'file_path': '/content/drive/MyDrive/Courses/RAG/C2_Llama3x-RAG-Workshop/dataset/Tri45-5files/_21-.pdf', 'file_type': 'application/pdf', 'file_size': 1112869, 'creation_date': '2024-12-12', 'last_modified_date': '2024-07-07'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='fdd12a8b-1414-4f97-a03a-f2f1c3640041', node_type='4', metadata={'page_label': '11', 'file_name': '_21-.pdf', 'file_path': '/content/drive/MyDrive/Courses/RAG/C2_Llama3x-RAG-Workshop/dataset/Tri45-5files/_21-.pdf', 'file_type': 'application/pdf', 'file_size': 1112869, 'creation_date': '2024-12-12', 'last_modified_date': '2024-07-07'}, hash='e218c15620c67718951366fea01abef8539031b1e85c538fc395c4e0c8e9fc8f')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='\\uf701 \\uf70a    - \\uf70b 11 \\n  \\uf70a\\uf70b    \\n\\uf70a \\uf712 \\uf70b     \\n\\uf70a\\uf712   \\n    \\uf70a   \\n\\uf70a\\uf70b   \\uf70a \\n\\uf70a \\uf70a   \\n \\uf712 \\uf712   \\n \\uf70a\\uf70b     \\uf70a \\n  \\uf712 \\uf70b     \\n\\uf70a   \\uf712 \\uf70a\\uf70b \\uf70a\\uf70b  \\n   \\uf70a\\uf70a \\uf70a  \\n  \\uf712 \\uf70b \\n \\uf712\\uf70b \\uf712\\uf70b\\uf70a  \\uf70e \\n\\uf712   \\uf70a  \\uf70a \\uf70b\\n  \\n      \\n      \\uf70e\\uf70b\\uf70b   \\n       \\uf70a\\uf712\\uf70b \\n     \\uf70a   \\uf70a\\uf70e\\uf70a \\uf70b \\n        \\n         \\uf70b \\uf70e\\uf70a \\uf712\\uf70b \\n     \\n \\uf712\\uf70b\\uf70a\\uf70b\\uf70b  \\n                                                      \\n                                                   \\n                                           ___________________ \\n                                    \\n     .  .  .   .    .   \\n.  .  .  .  .  \\n                                     ________________', mimetype='text/plain', start_char_idx=0, end_char_idx=2095, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.5962243557236705)], metadata={'9157334f-e405-4cf5-ae51-dad504191b28': {'page_label': '10', 'file_name': '_21-.pdf', 'file_path': '/content/drive/MyDrive/Courses/RAG/C2_Llama3x-RAG-Workshop/dataset/Tri45-5files/_21-.pdf', 'file_type': 'application/pdf', 'file_size': 1112869, 'creation_date': '2024-12-12', 'last_modified_date': '2024-07-07'}, '04447e70-06cc-442e-9754-ac54014d783f': {'page_label': '11', 'file_name': '_21-.pdf', 'file_path': '/content/drive/MyDrive/Courses/RAG/C2_Llama3x-RAG-Workshop/dataset/Tri45-5files/_21-.pdf', 'file_type': 'application/pdf', 'file_size': 1112869, 'creation_date': '2024-12-12', 'last_modified_date': '2024-07-07'}}, response_txt='     4 ')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNVgRgycmlYv"
      },
      "source": [
        "## Storing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bjDrdRag_3Q"
      },
      "outputs": [],
      "source": [
        "index.storage_context.persist(persist_dir=\"./storage\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp -r ./storage /content/drive/MyDrive/Courses/RAG/storage"
      ],
      "metadata": {
        "id": "-tfyMR-gCwC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Index"
      ],
      "metadata": {
        "id": "lt1RwgVU7Z2V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjcYRoSlhAAS"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "\n",
        "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
        "#storage_context = StorageContext.from_defaults(persist_dir=\"/content/drive/MyDrive/TrainModel/storage_tri45\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emO65gB34ZwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb3241f-3a88-4bd7-fb78-8d7bea3e4169"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaCPP(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7ad8c655e990>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x7ad8c5f3c900>, completion_to_prompt=<function completion_to_prompt at 0x7ad8c5f3c860>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, model_url='https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf', model_path='/tmp/llama_index/models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf', temperature=0.1, max_new_tokens=1024, context_window=8192, generate_kwargs={'temperature': 0.1, 'max_tokens': 1024}, model_kwargs={'n_ctx': 8192, 'verbose': True, 'repetition-penalty': 1.4, 'no_repeat_ngram_size': 4, 'n_gpu_layers': -1}, verbose=True)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "llm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model"
      ],
      "metadata": {
        "id": "GjbsXzuf7tH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf63167-bacd-40b1-e7b0-913626621c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HuggingFaceEmbedding(model_name='BAAI/bge-m3', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7ad654597510>, num_workers=None, max_length=8192, normalize=True, query_instruction=None, text_instruction=None, cache_folder=None, show_progress_bar=False)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "# Settings.chunk_size    = 3840\n",
        "# Settings.chunk_overlap = 256\n",
        "Settings.llm         = llm\n",
        "Settings.embed_model = embed_model"
      ],
      "metadata": {
        "id": "f_6dV79-ZIme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_index = load_index_from_storage(storage_context=storage_context)\n",
        "load_index"
      ],
      "metadata": {
        "id": "EhMWTAgoljrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f642bc03-5a91-4b1b-b7c0-4cf115ad56ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x7ad64a2f3890>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Query as Retriever in Vector Database only**\n",
        "\n",
        "Node Postprocessor   \n",
        "https://docs.llamaindex.ai/en/stable/module_guides/querying/node_postprocessors/"
      ],
      "metadata": {
        "id": "jqTs5-OK9L87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retrieval_engine = load_index.as_retriever(similarity_top_k=2)\n",
        "response         = retrieval_engine.retrieve(\"   \")\n",
        "display(Markdown(f\"{response[0]}\"))\n",
        "display(Markdown(f\"{response[1]}\"))"
      ],
      "metadata": {
        "id": "CACp9UHW8xEq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "7bce19ec-e65a-4701-a7ea-312476b55027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Node ID: 9157334f-e405-4cf5-ae51-dad504191b28\nText:      -  10\n  \n   \n    \n    \n ...\nScore:  0.623\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Node ID: 04447e70-06cc-442e-9754-ac54014d783f\nText:      -  11\n    \n   \n    \n\n      ...\nScore:  0.596\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Query with LLM\n",
        "Response Mode\n",
        "https://docs.llamaindex.ai/en/stable/module_guides/deploying/query_engine/response_modes/"
      ],
      "metadata": {
        "id": "IWUQw6aL_djU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "-fwNmti1euXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "llm.generate_kwargs={'temperature': 0.1, 'max_tokens': 512}\n",
        "\n",
        "query_engine = load_index.as_query_engine(\n",
        "    similarity_top_k=4 ,\n",
        "    streaming=True)\n",
        "response     = query_engine.query(\"   \")\n",
        "response.print_response_stream()\n",
        "#display(Markdown(f\"{response}\"))"
      ],
      "metadata": {
        "id": "1huqPzIX9pRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab3bb7c6-11ac-44ee-f1c8-04f41d4be835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    2039.96 ms\n",
            "llama_perf_context_print: prompt eval time =    2039.23 ms /  3667 tokens (    0.56 ms per token,  1798.23 tokens per second)\n",
            "llama_perf_context_print:        eval time =     859.58 ms /    35 runs   (   24.56 ms per token,    40.72 tokens per second)\n",
            "llama_perf_context_print:       total time =    2945.59 ms /  3702 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 1302 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    2039.96 ms\n",
            "llama_perf_context_print: prompt eval time =     589.02 ms /  1302 tokens (    0.45 ms per token,  2210.45 tokens per second)\n",
            "llama_perf_context_print:        eval time =     593.28 ms /    26 runs   (   22.82 ms per token,    43.82 tokens per second)\n",
            "llama_perf_context_print:       total time =    1231.54 ms /  1328 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.11 s, sys: 283 ms, total: 4.39 s\n",
            "Wall time: 4.36 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat Engine\n",
        "\n",
        "usage pattern guide.   \n",
        "https://docs.llamaindex.ai/en/stable/module_guides/deploying/chat_engines/usage_pattern/"
      ],
      "metadata": {
        "id": "iDcoUedn9rD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_engine = load_index.as_chat_engine(\n",
        "    llm=llm,\n",
        "    similarity_top_k=1,\n",
        "    chat_mode=\"condense_question\",\n",
        "    streaming=True,\n",
        "    verbose=True,\n",
        ")\n",
        "#chat_engine.reset()"
      ],
      "metadata": {
        "id": "6sxGxBIhRIcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collected_messages = []\n",
        "\n",
        "streaming_response = chat_engine.stream_chat(\"   \")\n",
        "for token in streaming_response.response_gen:\n",
        "    print(token, end=\"\")\n",
        "    collected_messages.append(token)\n",
        "\n",
        "full_message = ''.join(collected_messages)\n",
        "display(Markdown(f\"{full_message}\"))"
      ],
      "metadata": {
        "id": "h1Cwlo3WR7qp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "f5aad089-2b93-4206-9c11-e703e88189de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Querying with:    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 9 prefix-match hit, remaining 1376 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    2039.96 ms\n",
            "llama_perf_context_print: prompt eval time =     613.05 ms /  1376 tokens (    0.45 ms per token,  2244.51 tokens per second)\n",
            "llama_perf_context_print:        eval time =     797.93 ms /    35 runs   (   22.80 ms per token,    43.86 tokens per second)\n",
            "llama_perf_context_print:       total time =    1462.63 ms /  1411 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 4 "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "     4 "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rerank"
      ],
      "metadata": {
        "id": "SFfccRubVoQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.postprocessor.flag_embedding_reranker import (\n",
        "    FlagEmbeddingReranker,\n",
        ")\n",
        "rerank = FlagEmbeddingReranker(model=\"BAAI/bge-reranker-v2-m3\", top_n=5)"
      ],
      "metadata": {
        "id": "8y7Ljq_tV7p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "SfeeM9vxe9wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "query_engine = load_index.as_query_engine(\n",
        "    similarity_top_k=10,\n",
        "    streaming=True,\n",
        "    node_postprocessors=[rerank]\n",
        ")\n",
        "\n",
        "response = query_engine.query(\n",
        "    \"   \",\n",
        ")\n",
        "response.print_response_stream()"
      ],
      "metadata": {
        "id": "84jAOoIYXAEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG Summarization Tool"
      ],
      "metadata": {
        "id": "i2TqqaOKNfvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "g5MCqRhkgquS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "# load documents\n",
        "#documents = SimpleDirectoryReader(input_files=[\"metagpt.pdf\"]).load_data()\n",
        "documents = SimpleDirectoryReader(\n",
        "    input_files=[\"/content/drive/MyDrive/Dataset/Tri45-5files/_21-.pdf\"]).load_data()\n",
        "len(documents)"
      ],
      "metadata": {
        "id": "MYncLX1-RhxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = documents[:10]"
      ],
      "metadata": {
        "id": "H3Iu21nYlp-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "splitter = SentenceSplitter(chunk_size=3840 ,chunk_overlap=256)\n",
        "nodes    = splitter.get_nodes_from_documents(documents ,show_progress=True)"
      ],
      "metadata": {
        "id": "Jyz2A37pRe62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SummaryIndex\n",
        "\n",
        "summary_index  = SummaryIndex(nodes)\n",
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\",\n",
        "    use_async=True,\n",
        "    verbose=False,\n",
        "    streaming=True,\n",
        ")"
      ],
      "metadata": {
        "id": "47PzdGRXbSsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "llm.generate_kwargs={'temperature': 0.8, 'max_tokens': 2048}\n",
        "\n",
        "response = summary_query_engine.query(\n",
        "    \"  \"\n",
        ")\n",
        "response.print_response_stream()"
      ],
      "metadata": {
        "id": "95UqCAXxNkub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_source_nodes = len(response.source_nodes)\n",
        "print(f\"Number of source nodes: {num_source_nodes}\")\n",
        "\n",
        "# Loop over source nodes and print meta data\n",
        "for s in response.source_nodes:\n",
        "    print(f\"Node Score: {s.score}\")\n",
        "    print(s.node.metadata)"
      ],
      "metadata": {
        "id": "7k0MlskMNmAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced RAG (Routing, Sub-Questions)"
      ],
      "metadata": {
        "id": "nW5R89hCNpt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "\n",
        "# vector_tool = QueryEngineTool(\n",
        "#     index.as_query_engine(),\n",
        "#     metadata=ToolMetadata(\n",
        "#         name=\"vector_search\",\n",
        "#         description=\"Useful for searching for specific facts.\",\n",
        "#     ),\n",
        "# )\n",
        "\n",
        "# summary_tool = QueryEngineTool(\n",
        "#     index.as_query_engine(response_mode=\"tree_summarize\"),\n",
        "#     metadata=ToolMetadata(\n",
        "#         name=\"summary\",\n",
        "#         description=\"Useful for summarizing an entire document.\",\n",
        "#     ),\n",
        "# )"
      ],
      "metadata": {
        "id": "C_nL6E8rNovE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from llama_index.core.query_engine import RouterQueryEngine\n",
        "\n",
        "# query_engine = RouterQueryEngine.from_defaults(\n",
        "#     [vector_tool, summary_tool],\n",
        "#     select_multi=False,\n",
        "#     verbose=True\n",
        "# )\n",
        "\n",
        "# response = query_engine.query(\n",
        "#     \"Tell me about the song meet the grahams - why is it significant\"\n",
        "# )\n",
        "\n",
        "# display(Markdown(f\"{response}\"))\n",
        "# print(len(str(response)))"
      ],
      "metadata": {
        "id": "tYys-BjgNtwc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "hNTcEoQx07U1",
        "SFfccRubVoQN",
        "i2TqqaOKNfvk",
        "nW5R89hCNpt7"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cbc559f9058c457eb8b1daa325319636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_812f579aa68a4d008883a5d02f236770",
              "IPY_MODEL_10e0d888b6754e25976219b9bfe9ad82",
              "IPY_MODEL_45ce1610b1fc4c90bca5a2112cf07e07"
            ],
            "layout": "IPY_MODEL_0bd35319d3ed452d8aa8cd1f6c389343"
          }
        },
        "812f579aa68a4d008883a5d02f236770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d86021fa52540f9b93883bd679dd335",
            "placeholder": "",
            "style": "IPY_MODEL_d10282d1e87442588f58e0876a53ce62",
            "value": "Parsingnodes:100%"
          }
        },
        "10e0d888b6754e25976219b9bfe9ad82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7681f9dc7c5f401eb553b6e9528cc5e2",
            "max": 3039,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31fb31c0cb6442f482bef234266df26c",
            "value": 3039
          }
        },
        "45ce1610b1fc4c90bca5a2112cf07e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea1106b1b289421f85a8cf6592ce8e1a",
            "placeholder": "",
            "style": "IPY_MODEL_5505d5b11dea4b56b5e4980740802947",
            "value": "3039/3039[00:01&lt;00:00,1535.01it/s]"
          }
        },
        "0bd35319d3ed452d8aa8cd1f6c389343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d86021fa52540f9b93883bd679dd335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d10282d1e87442588f58e0876a53ce62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7681f9dc7c5f401eb553b6e9528cc5e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31fb31c0cb6442f482bef234266df26c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea1106b1b289421f85a8cf6592ce8e1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5505d5b11dea4b56b5e4980740802947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec69b3b922ec4c84b8efa67cf377f002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db2dabbdb3f74c6dbc33da2a2755a828",
              "IPY_MODEL_cfbc0c7a6291437fb9619c4faf9e11e6",
              "IPY_MODEL_6bbb2da5605545e884623e5180e2802f"
            ],
            "layout": "IPY_MODEL_c535e9d97bd342dc80630d982b222da6"
          }
        },
        "db2dabbdb3f74c6dbc33da2a2755a828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e107b5c4cb64562ba931f68602c18a6",
            "placeholder": "",
            "style": "IPY_MODEL_6023ef11b9284d0fa325bf3023854989",
            "value": "Generatingembeddings:100%"
          }
        },
        "cfbc0c7a6291437fb9619c4faf9e11e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a03d48901eb9428297a8af2d66770c1d",
            "max": 2048,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1459e943754e467c962c05520d7d57e0",
            "value": 2048
          }
        },
        "6bbb2da5605545e884623e5180e2802f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48b0ff3b29c14709a617208af54e34b6",
            "placeholder": "",
            "style": "IPY_MODEL_b859b06f01874309a09a9111382e4358",
            "value": "2048/2048[02:55&lt;00:00,10.19it/s]"
          }
        },
        "c535e9d97bd342dc80630d982b222da6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e107b5c4cb64562ba931f68602c18a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6023ef11b9284d0fa325bf3023854989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a03d48901eb9428297a8af2d66770c1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1459e943754e467c962c05520d7d57e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48b0ff3b29c14709a617208af54e34b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b859b06f01874309a09a9111382e4358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47218e5fece645e392f2024c794b7948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccd3446ba6c8472c8ef390908878774a",
              "IPY_MODEL_1f15914637004334bafdea1ba972f6ba",
              "IPY_MODEL_6e58d8863b214fac90472944d40501fa"
            ],
            "layout": "IPY_MODEL_75bb84f218824af594bb1459bd402f6b"
          }
        },
        "ccd3446ba6c8472c8ef390908878774a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0076d54f187b4ccc8d37037e7143f1aa",
            "placeholder": "",
            "style": "IPY_MODEL_60fde0d1762e42d9a9af76268f49bfd4",
            "value": "Generatingembeddings:100%"
          }
        },
        "1f15914637004334bafdea1ba972f6ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a817d115a7794764ae33dc5bf2f3416c",
            "max": 991,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f695330864b14abcbea95017447bf976",
            "value": 991
          }
        },
        "6e58d8863b214fac90472944d40501fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dff0831f819495093d96fa7c8ab2932",
            "placeholder": "",
            "style": "IPY_MODEL_4cf73b368ecf440f90804d82b1cdab63",
            "value": "991/991[01:21&lt;00:00,28.17it/s]"
          }
        },
        "75bb84f218824af594bb1459bd402f6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0076d54f187b4ccc8d37037e7143f1aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60fde0d1762e42d9a9af76268f49bfd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a817d115a7794764ae33dc5bf2f3416c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f695330864b14abcbea95017447bf976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6dff0831f819495093d96fa7c8ab2932": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cf73b368ecf440f90804d82b1cdab63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}